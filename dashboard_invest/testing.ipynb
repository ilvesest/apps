{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"p1001\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"p1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.0.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.0.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.0.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.0.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.0.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"p1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 3rd part imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLORS FROM .XLSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# native\n",
    "import datetime\n",
    "import os\n",
    "from functools import wraps\n",
    "from types import NoneType\n",
    "\n",
    "# local\n",
    "from dashboard.logic.constants import NONE_LIKE_LIST, nav_names\n",
    "from dashboard.logic.io import getNewestFilename, total_assets, \\\n",
    "    downloadSheet, getOldestFilename, logError\n",
    " \n",
    "\n",
    "# 3rd\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "  \n",
    "\n",
    "def getPreviousFilename(files: list[str], ts_format:str=\"%Y-%m-%d_%H:%M:%S\") -> str:\n",
    "    \"\"\"Returns the filename with oldest timestamp\"\"\"\n",
    "    \n",
    "    if len(files) == 1: \n",
    "        return files[0]\n",
    "    \n",
    "    return sorted(files, key=lambda x: datetime.datetime.strptime(x[:19], ts_format))[1] \n",
    "    \n",
    "def readXlsx(route: str, newest_file: bool=True) -> DDF:\n",
    "\n",
    "    # Open the downloaded .xlsx file with openpyxl\n",
    "    path_to_file = os.path.join(\"dashboard\", \"cache\", route)\n",
    "    file_name = getNewestFilename(os.listdir(path_to_file)) if newest_file else getPreviousFilename(os.listdir(path_to_file))\n",
    "    full_rel_path = os.path.join(path_to_file, file_name)\n",
    "\n",
    "    # read .xlsx w/ openpyxl & select the worksheet\n",
    "    workbook = openpyxl.load_workbook(full_rel_path, data_only=True, read_only=True)\n",
    "    sheet_name = workbook.sheetnames[0]\n",
    "    worksheet = workbook[sheet_name]\n",
    "\n",
    "    # read .xslx with pandas & get number of rows & cols accurately\n",
    "    df_pandas = pd.read_excel(io=full_rel_path, sheet_name=sheet_name, header=None)\n",
    "    max_row = df_pandas.index.max() + 1\n",
    "    max_col = df_pandas.columns.max() + 1\n",
    "\n",
    "    # Read in the rows\n",
    "    rows = [row for row in worksheet.iter_rows(min_row=1, max_row=max_row, max_col=max_col)]\n",
    "\n",
    "    row_values = [] # create an empty list to hold the cell values\n",
    "    # iterate over the rows and columns to capture each cell properties\n",
    "    for row in rows:\n",
    "        cell_values = []\n",
    "        for cell in row:\n",
    "            # get the cell value, color, fill & font style\n",
    "            cell_value = np.nan if cell.data_type in ['f'] or cell.value is None else cell.value\n",
    "            \n",
    "            fill_obj = cell.fill\n",
    "            cell_color = fill_obj.start_color.index if not isinstance(fill_obj, NoneType) else np.nan\n",
    "            cell_color = 'FFFFFFFF' if cell_color in ['00000000', None, NoneType, np.nan] else cell_color\n",
    "            \n",
    "            #cell_fill = cell.fill.fill_type if cell.fill else np.nan\n",
    "            \n",
    "            cell_font = cell.font\n",
    "            \n",
    "            font_weight = 'bold' if not isinstance(cell_font, NoneType) and cell_font.b else 'normal'\n",
    "            \n",
    "            # append the cell value, color, and fill to the list\n",
    "            cell_values.append({'value': cell_value, \n",
    "                                'color': f\"#{cell_color[2:]}\" if isinstance(cell_color, str) else np.nan,\n",
    "                                'font-weight': font_weight})\n",
    "\n",
    "        row_values.append(cell_values)\n",
    "\n",
    "    # close workbook when read_only=True\n",
    "    if workbook.read_only:\n",
    "        workbook.close()\n",
    "\n",
    "    # create a pandas dataframe from the list of cell values\n",
    "    return DDF(row_values)\n",
    "\n",
    "def getMetaDataDict(route_name: str) -> dict:\n",
    "    \"\"\"Returns sheet metadata dictionary based on route name.\"\"\"\n",
    "    return nav_names[[k for k,v in nav_names.items() if nav_names[k]['route_name'] == route_name][0]]\n",
    "\n",
    "def formatToDollars(value, precision: int=2):\n",
    "    \"\"\"Format number to have commas separating thousans and leading $ sign.\"\"\"\n",
    "    if value == np.nan or pd.isna(value):\n",
    "        return value\n",
    "    try:\n",
    "        float_value = float(value)\n",
    "        return f\"${float_value:,.{precision}f}\"\n",
    "    except ValueError:\n",
    "        return value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DECORATORS\n",
    "def ioCacheAndLog(\n",
    "    url: str,\n",
    "    route: str,\n",
    "    testing: bool=False):\n",
    "    \n",
    "    def my_decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            \n",
    "            if not testing:\n",
    "            \n",
    "                # delete oldest file if 3 files present\n",
    "                cache_path = os.path.join(\"dashboard\", \"cache\", route)\n",
    "                if not os.path.exists(cache_path):\n",
    "                    os.mkdir(cache_path)\n",
    "                \n",
    "                files = os.listdir(cache_path)\n",
    "                while len(files) > 2:\n",
    "                    oldest_file = getOldestFilename(files=files)\n",
    "                    files = [file for file in files if file != oldest_file]\n",
    "                    os.remove(os.path.join(cache_path, oldest_file))\n",
    "                \n",
    "                # download google sheet as .xlsx file\n",
    "                downloadSheet(url=url, file_path=cache_path, route=route)\n",
    "            \n",
    "            try:\n",
    "                ddf = readXlsx(route=route, newest_file=True)\n",
    "                result = func(ddf)\n",
    "                # if any errors occured except block is executed\n",
    "                return result\n",
    "            \n",
    "            # read data from cache\n",
    "            except Exception as e:\n",
    "                \n",
    "                if not testing:\n",
    "                    # capture and save occurred error log\n",
    "                    logError(route=route, exception=e)\n",
    "                else:\n",
    "                    print(e)\n",
    "                \n",
    "                # read data from the previous cached file\n",
    "                ddf = readXlsx(route=route, newest_file=False)\n",
    "                newest_file = getNewestFilename(files)\n",
    "                os.remove(os.path.join(cache_path, newest_file))\n",
    "                \n",
    "                result = func(ddf)\n",
    "                return result\n",
    "        return wrapper\n",
    "    \n",
    "    return my_decorator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addButton(df: pd.DataFrame,\n",
    "                  col_names: list[str]=None,\n",
    "                  popover_style_str: str=\"\",\n",
    "                  button_name: str=\"Details\",\n",
    "                  button_class: str=\"btn btn-secondary btn-sm\",\n",
    "                  data_bs_html: str=\"true\",\n",
    "                  data_bs_toggle: str=\"popover\",\n",
    "                  data_bs_trigger: str=\"focus\",\n",
    "                  button_style: str=\"--bs-btn-font-size: .85rem;\"):\n",
    "        \"\"\"Add button html to the value-dict.\"\"\"\n",
    "        def add_button(value):\n",
    "            if value in NONE_LIKE_LIST:\n",
    "                return value\n",
    "            \n",
    "            html_string = \" \".join(\n",
    "                (\n",
    "                f'<button type=\"button\" class=\"{button_class}\"', \n",
    "                f'data-bs-content=\"<div style=\"{popover_style_str}\">{value}</div>\"',\n",
    "                f'data-bs-html=\"{data_bs_html}\" data-bs-toggle={data_bs_toggle} data-bs-trigger=\"{data_bs_trigger}\"', \n",
    "                f'style=\"{button_style}\">{button_name}</button>'\n",
    "                )\n",
    "            )\n",
    "            return html_string \n",
    "        \n",
    "        # apply to specified columns\n",
    "        df[col_names] = df[col_names].applymap(add_button)\n",
    "        \n",
    "        # return entire DF\n",
    "        return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stocks Watchlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddf = readXlsx('stocks_watchlist')\n",
    "metadata = getMetaDataDict(route_name='stocks_watchlist')\n",
    "\n",
    "@ioCacheAndLog(url=metadata['url'], route=metadata['route_name'], testing=True)\n",
    "def stocks_watchlist_script(ddf:DDF) -> dict:\n",
    "    \"\"\"Return dict of {'obj_name': object}. Object can be pd.Series, DF, styler.\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # get dict of DDFs\n",
    "    ddfs = ddf.getDdfDict({\n",
    "        'disclaimer': ('contains', 'These Valuations', 'down'),\n",
    "        'watch': ('contains', \"Neil's Value\", 'down', 0)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # DISCLAIMER DF\n",
    "    df_disc = ddfs['disclaimer']\n",
    "\n",
    "    # add period end of the sentence if not so\n",
    "    df_disc = DDF(df_disc).v[0].to_frame().rename(columns={0: 'info'})\n",
    "    df_disc.loc[:,'info'] = [x + '.' if x[-1] != '.' else x for x in df_disc['info']]\n",
    "\n",
    "    # add color column and set it as cat for ordering purposes\n",
    "    df_disc['color'] = ['warning', 'success', 'warning', 'success', 'success', 'danger']\n",
    "    df_disc['color'] = pd.Categorical(df_disc['color'],\n",
    "                                      categories=['success', 'warning', 'danger'],\n",
    "                                      ordered=True)\n",
    "\n",
    "    # add icon_id column\n",
    "    icon_dict = {'warning': 'exclamation-triangle-fill', 'success': 'check-lg', 'danger':'exclamation-octagon-fill'}\n",
    "    df_disc['icon_id'] = df_disc['color'].map(icon_dict)\n",
    "    df_disc = df_disc.sort_values('color')\n",
    "    \n",
    "    # add 'df_disc' to results\n",
    "    results['df_disc'] = df_disc\n",
    "    \n",
    "    # STOCKS WATCHLIST DF\n",
    "    ddf_watch = ddfs['watch']\n",
    "    df_watch_styled = (ddf_watch\n",
    "        .setHeader() # set header\n",
    "        .addButton(keys=['color', 'font-weight'], col_names=['Notes']) # add button\n",
    "        .setStyle(keys=['color', 'font-weight'], subset=pd.IndexSlice[:, :'Sector'])\n",
    "        .hide(axis='index')\n",
    "        .set_table_attributes('class=\"stockwatch\"')\n",
    "    )\n",
    "    # add to results\n",
    "    results['df_watch_styled'] = df_watch_styled\n",
    "    \n",
    "    return results\n",
    "\n",
    "#stocks_watchlist_script(ddf)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset</th>\n",
       "      <th>risk</th>\n",
       "      <th>notes</th>\n",
       "      <th>risk_word</th>\n",
       "      <th>li_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver</td>\n",
       "      <td>1</td>\n",
       "      <td>Unlikely to be confiscated &amp; good inflation he...</td>\n",
       "      <td>VERY LOW</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Farmland</td>\n",
       "      <td>1</td>\n",
       "      <td>Holds value extremely well and can be used for...</td>\n",
       "      <td>VERY LOW</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gold</td>\n",
       "      <td>2</td>\n",
       "      <td>Risk of Confiscation under a GOLD standard sce...</td>\n",
       "      <td>LOW</td>\n",
       "      <td>info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crypto</td>\n",
       "      <td>3</td>\n",
       "      <td>Risk of further/continued regulation or the cu...</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cash</td>\n",
       "      <td>3</td>\n",
       "      <td>WILL be phased out when CBDC launches (3-5 yea...</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bonds</td>\n",
       "      <td>3</td>\n",
       "      <td>Russia is a great example of paper certificate...</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Businesses</td>\n",
       "      <td>3</td>\n",
       "      <td>Inflation = Consumer cut in spending = RECESSI...</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pensions</td>\n",
       "      <td>3</td>\n",
       "      <td>Collapse risk! (Watch my YT video on this here...</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Real Estate</td>\n",
       "      <td>4</td>\n",
       "      <td>High risk of declines in late 2022 and through...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>danger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stock Markets</td>\n",
       "      <td>4</td>\n",
       "      <td>High risk of declines once USA interest rates ...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>danger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Economy</td>\n",
       "      <td>4</td>\n",
       "      <td>On Life Support right now, expect a recession ...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>danger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Unemployment</td>\n",
       "      <td>4</td>\n",
       "      <td>Employment scarring likely, save up as much as...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>danger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>COLLAPSE</td>\n",
       "      <td>4</td>\n",
       "      <td>Getting more and more real every day. Banking ...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>danger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            asset  risk                                              notes  \\\n",
       "0          Silver     1  Unlikely to be confiscated & good inflation he...   \n",
       "1        Farmland     1  Holds value extremely well and can be used for...   \n",
       "2            Gold     2  Risk of Confiscation under a GOLD standard sce...   \n",
       "3          Crypto     3  Risk of further/continued regulation or the cu...   \n",
       "4            Cash     3  WILL be phased out when CBDC launches (3-5 yea...   \n",
       "5           Bonds     3  Russia is a great example of paper certificate...   \n",
       "6      Businesses     3  Inflation = Consumer cut in spending = RECESSI...   \n",
       "7        Pensions     3  Collapse risk! (Watch my YT video on this here...   \n",
       "8     Real Estate     4  High risk of declines in late 2022 and through...   \n",
       "9   Stock Markets     4  High risk of declines once USA interest rates ...   \n",
       "10        Economy     4  On Life Support right now, expect a recession ...   \n",
       "11   Unemployment     4  Employment scarring likely, save up as much as...   \n",
       "12       COLLAPSE     4  Getting more and more real every day. Banking ...   \n",
       "\n",
       "   risk_word li_group  \n",
       "0   VERY LOW  success  \n",
       "1   VERY LOW  success  \n",
       "2        LOW     info  \n",
       "3     MEDIUM  warning  \n",
       "4     MEDIUM  warning  \n",
       "5     MEDIUM  warning  \n",
       "6     MEDIUM  warning  \n",
       "7     MEDIUM  warning  \n",
       "8       HIGH   danger  \n",
       "9       HIGH   danger  \n",
       "10      HIGH   danger  \n",
       "11      HIGH   danger  \n",
       "12      HIGH   danger  "
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dashboard.logic.constants import styling_vars\n",
    "from dashboard.logic.plots import pie_chart\n",
    "from dashboard.logic.io import findRefRowCol\n",
    "\n",
    "def calcTotalUSD(df: pd.DataFrame, col_name:str) -> pd.DataFrame:\n",
    "    \"\"\"Calculate total value if '#ERROR!' in col_name.\"\"\"\n",
    "    total_idx = np.where(a.apply(lambda x: x.str.contains(r\"Total \\(USD\\)\") == True))[0][0]\n",
    "    exclude_cols = ['Monthly Income', np.nan]\n",
    " \n",
    "    # check if total value has ERROR msg\n",
    "    if df.loc[total_idx, col_name] in [\"#ERROR!\", \"#NAME?\"]:\n",
    "        df.loc[total_idx, col_name] = 0\n",
    "    else:\n",
    "        return df\n",
    "     \n",
    "    # exclude error fields and monthly income\n",
    "    df_mask = df[(~df[col_name].isin(['#ERROR!', '#NAME?'])) & (~df['Asset Class'].isin(exclude_cols))]\n",
    "    \n",
    "    # str to float and calc total sum\n",
    "    df_mask.loc[col_name] = df_mask[col_name].replace(r\"[\\$,]\", \"\", regex=True).astype(float)\n",
    "    \n",
    "    total = df_mask[col_name].sum()\n",
    "    df.loc[total_idx, col_name] = \"${0:,.2f}\".format(total) # format numbers back to string\n",
    "\n",
    "    return df\n",
    "\n",
    "def getRelContainsIdx(df: pd.DataFrame, pattern: str, na=None):\n",
    "    \"\"\"Return relative row index where pattern is found.\"\"\"\n",
    "    return np.where(df.apply(lambda x: x.str.contains(pattern, na=np.nan) == True))[0][0]\n",
    "\n",
    "class DDF(pd.DataFrame):\n",
    "    \n",
    "    EXCLUSIONS = NONE_LIKE_LIST\n",
    "    \n",
    "    def __init__(self, data=None, index=None, columns=None, dtype=None, copy=False):\n",
    "        super().__init__(data=data, index=index, columns=columns, dtype=dtype, copy=copy)  \n",
    "    \n",
    "    @property\n",
    "    def v(self):\n",
    "        def extract_value(value_dict):\n",
    "            return value_dict.get('value')\n",
    "        return self.applymap(extract_value)\n",
    "\n",
    "    def prop(self, property: str):\n",
    "        def extract_property(value_dict):\n",
    "            return value_dict.get(property)\n",
    "        return self.applymap(extract_property)\n",
    "    \n",
    "    def getDdfDict(self, references_dict: dict[str, tuple[str,str,str]]) -> dict[str]:\n",
    "        \"\"\"Return dictionary of subset DDF-s based on reference dict.\n",
    "        \n",
    "        Args:\n",
    "\n",
    "            references_dict (dict): Dictionary of df_name: tuple('method', 'string' , 'direction', int('col_idx1)).\n",
    "                method has 2 options ['contains' and 'equals'], 'direction' has 3 options \n",
    "                ['one', 'down', 'up'] where one means only one line needs to be parsed, 'up' and 'down'\n",
    "                respectively correspond to the parsing direction from the reference point.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary of {'df_name': df}\"\"\"\n",
    "        \n",
    "        \n",
    "        def get_reference_row_col_idx(df: pd.DataFrame, pattern: str, method: str='contains') -> tuple[int, int]:\n",
    "            \"\"\"Find reference row and column numeric index values.\n",
    "\n",
    "            Args:\n",
    "                pattern (str): Character sequence or regular expression.\n",
    "                method (str, optional): Finding reference via pattern within the text ('contains')\n",
    "                    or equalling the value exactly ('equals'). Defaults to 'contains'.\n",
    "\n",
    "            Raises:\n",
    "                ValueError: Raises error if other than ['contains', 'equals'] is specified for the method.\n",
    "\n",
    "            Returns:\n",
    "                tuple[int, int]: Tuple of ['row_i', 'col_i']\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            # validate that method is correctly entered\n",
    "            if method not in ['contains', 'equals']:\n",
    "                raise ValueError(f\"{method} can take only values: 'contains' or 'equals'!\")\n",
    "            \n",
    "            if method == 'contains':\n",
    "                index, column = np.where(df.apply(lambda x: x.str.contains(pattern) == True))\n",
    "                return index[0], column[0]\n",
    "            \n",
    "            if method == 'equals':\n",
    "                index, column = np.where(df == pattern)\n",
    "                return index[0], column[0]\n",
    "    \n",
    "        def get_DDF(ddf: DDF, \n",
    "            row_idx1: int=None, \n",
    "            row_idx2:int=None, \n",
    "            col_idx1: int=None, \n",
    "            col_idx2: int=None,\n",
    "            col_0: bool=True, \n",
    "            direction='down') -> DDF:\n",
    "            \"\"\"Slice DF till the first occuring empty row in given direction.\n",
    "\n",
    "            Args:\n",
    "                col_0 (bool, optional): If col_idx1 is actually first column. Defaults to True.\n",
    "                direction (str, optional): Slice upwards or downwards from given row index. Defaults to 'down'.\n",
    "\n",
    "            Raises:\n",
    "                ValueError: If no row indices are specified.\n",
    "\n",
    "            Returns:\n",
    "                pd.DataFrame\n",
    "            \"\"\"\n",
    "            \n",
    "            # assert that at least one of the row indices is specified\n",
    "            if row_idx1 is None and row_idx2 is None:\n",
    "                raise ValueError(f\"Both row indices can't equal {None}!\") \n",
    "            \n",
    "            # if column index is not the first column then None\n",
    "            col_idx1 = col_idx1 if col_0 is True else None\n",
    "            \n",
    "            # find missing row index\n",
    "            if direction == 'down':\n",
    "                nan_mask = ddf.v.loc[row_idx1:,col_idx1:col_idx2].isna().all(axis='columns')\n",
    "                row_idx2 = None if nan_mask.sum() == 0 else nan_mask.idxmax()\n",
    "\n",
    "            if direction == 'up':\n",
    "                nan_mask = ddf.v.loc[:row_idx2,col_idx1:col_idx2].isna().all(axis='columns')\n",
    "                row_idx1 = None if nan_mask.sum() == 0 else nan_mask[::-1].idxmax() + 1\n",
    "                row_idx2 += 1\n",
    "                \n",
    "            return DDF(ddf.loc[row_idx1:row_idx2,col_idx1:col_idx2])\n",
    "        \n",
    "        \n",
    "        # set all cols str type, NaN -> 'nan'\n",
    "        df = self.v.astype('O')\n",
    "        \n",
    "        # {ddf name: ddf} dictionary\n",
    "        ddfs = {}\n",
    "        for k,v in references_dict.items():\n",
    "            \n",
    "            # find reference position (row index & col index)\n",
    "            row_i, col_i = get_reference_row_col_idx(df, pattern=v[1], method=v[0])\n",
    "            \n",
    "            # shift ref position if specified\n",
    "            col_i = v[3] if len(v) == 4 else col_i\n",
    "            \n",
    "            if v[2] == 'one':\n",
    "                ddfs[k] = DDF(self.loc[row_i,col_i:])\n",
    "            if v[2] == 'down':\n",
    "                ddfs[k] = get_DDF(self, row_idx1=row_i, col_idx1=col_i, direction=v[2])\n",
    "            if v[2] == 'up':\n",
    "                ddfs[k] = get_DDF(self, row_idx2=row_i, col_idx1=col_i, direction=v[2])\n",
    "\n",
    "        # strip all NaN cols and rows\n",
    "        ddfs_clean = {}\n",
    "        for k,ddf_ in ddfs.items():\n",
    "            \n",
    "            # drop any NaN-s in the row\n",
    "            if isinstance(ddf_.v, pd.Series):\n",
    "                df_ = ddf_.v.dropna(how='any', axis='rows')\n",
    "                ddfs_clean[k] = DDF(ddf_.loc[df_.index,0])\n",
    "            # drop \n",
    "            else:\n",
    "                df_ = (ddf_.v \n",
    "                    .dropna(how='all', axis='columns')\n",
    "                    .dropna(how='all', axis='rows')\n",
    "                )\n",
    "                ddfs_clean[k] = DDF(ddf_.loc[df_.index, df_.columns])\n",
    "        \n",
    "        return ddfs_clean\n",
    "    \n",
    "    def addButton(self, keys: list=[],\n",
    "                  col_names: list[str]=None,\n",
    "                  button_name: str=\"Details\",\n",
    "                  button_class: str=\"btn btn-secondary btn-sm\",\n",
    "                  data_bs_html: str=\"true\",\n",
    "                  data_bs_toggle: str=\"popover\",\n",
    "                  data_bs_trigger: str=\"focus\",\n",
    "                  button_style: str=\"--bs-btn-font-size: .85rem;\"):\n",
    "        \"\"\"Add button html to the value-dict.\"\"\"\n",
    "        def add_button(value_dict):\n",
    "            \n",
    "            # select only specified keys and values that are not none-like\n",
    "            style_args = [f\"{key}:{val}\" for key,val in value_dict.items() \\\n",
    "                if key in keys and val not in DDF.EXCLUSIONS]\n",
    "            \n",
    "            # concat style args into one string\n",
    "            style_str = \";\".join(style_args) if len(style_args) > 0 else \"\"\n",
    "            data_value = value_dict['value'] \n",
    "                      \n",
    "            html_string = \" \".join(\n",
    "                (\n",
    "                f'<button type=\"button\" class=\"{button_class}\"', \n",
    "                f'data-bs-content=\"<div style=\"{style_str}\">{data_value}</div>\"',\n",
    "                f'data-bs-html=\"{data_bs_html}\" data-bs-toggle={data_bs_toggle} data-bs-trigger=\"{data_bs_trigger}\"', \n",
    "                f'style=\"{button_style}\">{button_name}</button>'\n",
    "                )\n",
    "            )\n",
    "            return {'value':html_string} if data_value not in DDF.EXCLUSIONS else {'value':\"\"}\n",
    "        \n",
    "        # apply to specified columns\n",
    "        self[col_names] = DDF(self[col_names]).applymap(add_button)\n",
    "        \n",
    "        # return entire DDF\n",
    "        return DDF(self)\n",
    "        \n",
    "    def replaceValues(self, df:pd.DataFrame, keys: list=None):\n",
    "        \"\"\"Replace values in DDF based on values in DF. Return DDF with DF dimensions.\"\"\"\n",
    "        df_idx, df_cols = df.index, df.columns\n",
    "        for i in df_idx:\n",
    "            for c in df_cols:\n",
    "                self.loc[i,c]['value'] = df.loc[i,c]\n",
    "        return DDF(self.loc[df_idx,df_cols])\n",
    "\n",
    "    def replaceProperties(self, subset: pd.IndexSlice, property_dict: dict):\n",
    "        \"\"\"Replace values in DDF based on property_dict keys and values.\"\"\"\n",
    "        \n",
    "        def replace_values(value_dict):\n",
    "            new_value_dict = {k:v for k,v in value_dict.items() if k not in property_dict.keys()}\n",
    "            return new_value_dict | property_dict\n",
    "        \n",
    "        if isinstance(self.loc[subset], pd.Series):\n",
    "            self.loc[subset] = self.loc[subset].apply(replace_values)\n",
    "            return DDF(self)\n",
    "        else:\n",
    "            self.loc[subset] = self.loc[subset].applymap(replace_values)\n",
    "            return DDF(self)\n",
    "               \n",
    "\n",
    "    def setHeader(self, header_idx: int=None, col_names: list[str]=None):\n",
    "        \"\"\"Returns DDF with specified header.\"\"\"\n",
    "        \n",
    "        if col_names is not None:\n",
    "            self.columns = col_names\n",
    "            return self\n",
    "        \n",
    "        header_idx = self.index[0] if header_idx is None else header_idx\n",
    "        \n",
    "        columns = self.v.loc[header_idx]\n",
    "        index = self.loc[header_idx+1:].index\n",
    "        \n",
    "        return DDF(data=self.loc[header_idx+1:].values, index=index, columns=columns)\n",
    "\n",
    "    def setIndex(self, keys):\n",
    "        index_array = self.v[keys]\n",
    "        cols_to_drop = [keys] if isinstance(keys, str) else keys\n",
    "        return DDF(self.set_index(index_array).drop(columns=cols_to_drop))\n",
    "    \n",
    "    def setStyle(self, keys: list=[], subset:pd.IndexSlice=pd.IndexSlice[:,:]):\n",
    "        \"\"\"Return the styled values DF.\"\"\"\n",
    "        def get_style_kwargs(value_dict):\n",
    "            return {k:v for k,v in value_dict.items() if k in keys}\n",
    "\n",
    "        df_style = self.v.style.format(precision=2)\n",
    "        for row_i in self.index:\n",
    "            for col in self.columns:\n",
    "                df_style.set_properties(subset=pd.IndexSlice[row_i,col], **get_style_kwargs(self.loc[row_i, col]))\n",
    "        return df_style\n",
    "      \n",
    "\n",
    "#ddf = readXlsx('investments')\n",
    "\n",
    "metadata = getMetaDataDict(route_name='investments')\n",
    "\n",
    "@ioCacheAndLog(url=metadata['url'], route=metadata['route_name'], testing=True)\n",
    "def investments_script(ddf:DDF) -> dict:\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # read in sub DDFs\n",
    "    ddfs = ddf.getDdfDict({\n",
    "        'main' : (\"contains\", \"Monthly Income\", 'up'),\n",
    "        'ads' : (\"contains\", 'My Finance Course', 'down'),\n",
    "        'announce' : (\"contains\", \"Jul 2022: I'm\", 'up'),\n",
    "        'advice' : (\"contains\", '3x Excellent', 'up'),\n",
    "        'warning_msg' : (\"contains\", 'NOTE: Occasionally', 'one'),\n",
    "        'risk' : (\"equals\", \"RISK\", 'down', 0),\n",
    "        'historical' : (\"equals\", \"My Historical Investments\", \"down\"),\n",
    "        'cash_pos' : (\"contains\", \"CASH POSITION\", 'one'),\n",
    "        'general_notes' : (\"equals\", \"GENERAL NOTES\", \"down\"),\n",
    "        'success' : (\"equals\", \"Investment Success:\", \"down\")\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # ADS\n",
    "    ddf_ads = ddfs['ads']\n",
    "    ddf_ads.setHeader(col_names=['text', 'hyperlink'])\n",
    "    \n",
    "    df_ads = ddf_ads.v\n",
    "    df_ads['icon'] = df_ads.text.str.extract(r\"\\s*(\\S)\")\n",
    "    df_ads['text'] = df_ads.text.str.extract(r\"(\\b.+[^\\s])\")\n",
    "\n",
    "    # manually generated headers\n",
    "    # headers = ['My Finance Course', 'My UK Property Courses', 'Mentoring', 'Metals Globally', \n",
    "    #         'Metals USA', 'Metals UK', 'Crypto Security', 'Stock Platform', 'Bank Account']\n",
    "    \n",
    "    # dynamically generated headers\n",
    "    headers = [\" \".join(string.split()[:4]) for string in df_ads['text']]\n",
    "    \n",
    "    icons_html_dict = {'My Finance Course' : 'bi bi-graph-up-arrow', \n",
    "                        'My UK Property Courses' : 'bi bi-house', \n",
    "                        'Mentoring' : 'fa-regular fa-handshake', \n",
    "                        'Metals Globally': 'bi bi-globe-asia-australia', \n",
    "                        'Metals USA': 'bi bi-currency-dollar', \n",
    "                        'Metals UK': 'bi bi-currency-pound', \n",
    "                        'Crypto Security': 'bi bi-currency-bitcoin', \n",
    "                        'Stock Platform': 'fa-solid fa-chart-column', \n",
    "                        'Bank Account': 'bi bi-bank'}\n",
    "\n",
    "    df_ads['header'] = headers\n",
    "    \n",
    "    df_ads['new_icon_html'] = df_ads['header'].map(icons_html_dict)\n",
    "    \n",
    "    results['df_ads'] = df_ads # add ADS DF to results\n",
    "    \n",
    "    \n",
    "    # MAIN DF\n",
    "    ddf_main = DDF(ddfs['main'].iloc[:,:3])\n",
    "    ddf_main = (ddf_main\n",
    "        .setHeader(col_names=['Asset Class', 'Total Value', 'Notes']) # set header\n",
    "        .addButton(keys=['color', 'font-weight'], col_names=['Notes']) # add button\n",
    "    )\n",
    "    \n",
    "    df_main = ddf_main.v\n",
    "    df_main = calcTotalUSD(df_main, col_name='Total Value') # calc total if errors\n",
    "    df_plot = df_main.copy() # set indermediet variable for pie chart later\n",
    "    df_main['Total Value'] = df_main['Total Value'].apply(formatToDollars) # apply $0,00.00 format\n",
    "    df_main = df_main.fillna('').replace('#NAME?', '#ERROR!') # replace values if present\n",
    "    \n",
    "    # get styled object\n",
    "    df_main_styled = (ddf_main\n",
    "        .replaceValues(df_main) # replace values based on DF vals\n",
    "        .replaceProperties(pd.IndexSlice[df_main.query(\"`Asset Class` == 'Total (USD)'\").index, :], {\"color\": \"#E2B842\"})\n",
    "        .replaceProperties(pd.IndexSlice[findRefRowCol(df_main, r'Monthly Income')[0], :], {\"color\": \"grey\", \"font-style\": \"italic\"})\n",
    "        .replaceProperties(pd.IndexSlice[df_main.query(\"`Total Value` == '#ERROR!'\").index, \"Total Value\"], {\"color\": \"red\", \"opacity\": \"0.75\"})\n",
    "        .setStyle(keys=['color', 'font-weight', 'opacity', 'font-style'])\n",
    "        .hide(axis='index')\n",
    "    )\n",
    "    \n",
    "    results['df_main_styled'] = df_main_styled # add to results\n",
    "    \n",
    "    # PIE-CHART\n",
    "    # add underscores to col names\n",
    "    df_plot.columns = df_plot.columns.map(lambda x: x.replace(\" \", \"_\"))\n",
    "    \n",
    "    # set 'Asset_Class' as new index\n",
    "    df_plot = (df_plot\n",
    "        .set_index('Asset_Class') \n",
    "        .drop(columns=['Notes'])\n",
    "        .loc[:'Total (USD)'].iloc[:-1]\n",
    "        .query(\"Total_Value != '#ERROR!'\")\n",
    "        .reset_index()\n",
    "        .dropna()\n",
    "    )\n",
    "    df_plot['Total_Value'] = df_plot['Total_Value'].astype(float)\n",
    "    #a = 'Total_Value'\n",
    "    #return df_plot[a] / df_plot[a].sum() * 100\n",
    "    \n",
    "    # create plot object\n",
    "    pie_chart_plot = pie_chart(\n",
    "        df=df_plot,\n",
    "        x='Asset_Class',\n",
    "        y='Total_Value',\n",
    "        background_color=styling_vars['bg-color'],\n",
    "        legend_place='below',\n",
    "        fig_height=720,\n",
    "        label_distance=3.2,\n",
    "        label_kwargs=dict(text_font_size='9pt', text_align='center', text_font_style='bold'),\n",
    "        radius=0.62,\n",
    "        sizing_mode='scale_width'\n",
    "    )\n",
    "\n",
    "    # ASSET RISKS\n",
    "    ddf_risk = ddfs['risk']\n",
    "    ddf_risk = ddf_risk.setHeader(col_names=['asset', 'risk', 'notes'])\n",
    "    \n",
    "    df_risk = ddf_risk.v\n",
    "    idx1 = getRelContainsIdx(df_risk, 'RISK') # find relative index of pattern\n",
    "    idx2 = getRelContainsIdx(df_risk, 'CODE') # find relative index of pattern\n",
    "    df_risk = df_risk.iloc[idx1+1:idx2,] # cut df\n",
    "    df_risk.iloc[-2].notes += \". \" + df_risk.iloc[-1, -1]\n",
    "    df_risk = df_risk.iloc[:-1].reset_index(drop=True)\n",
    "    df_risk['risk'] = [1, 1, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4]\n",
    "    df_risk['risk_word'] = df_risk['risk'].replace({1:'VERY LOW', 2: 'LOW', 3: 'MEDIUM', 4: 'HIGH'})\n",
    "    df_risk['li_group'] = df_risk['risk'].replace({1: 'success', 2: 'info', 3: 'warning', 4: 'danger'})\n",
    "    \n",
    "    return df_risk\n",
    "    \n",
    "    results['df_risk'] = df_risk # add to results\n",
    "    \n",
    "    return results\n",
    "\n",
    "investments_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[357], line 30\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# plot_js, plot_div = components(pie_chart_plot) # create static plot objects\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# results['plot_js'] = plot_js\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# results['plot_div'] = plot_div\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m# GENERAL ADVICE\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m results[\u001b[39m'\u001b[39m\u001b[39mdf_advice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ddfs[\u001b[39m'\u001b[39m\u001b[39madvice\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mv\n\u001b[1;32m     32\u001b[0m \u001b[39m# GENERAL NOTES\u001b[39;00m\n\u001b[1;32m     33\u001b[0m df_gen \u001b[39m=\u001b[39m ddfs[\u001b[39m'\u001b[39m\u001b[39mgeneral_notes\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mv\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ddfs' is not defined"
     ]
    }
   ],
   "source": [
    "    # plot_js, plot_div = components(pie_chart_plot) # create static plot objects\n",
    "    # results['plot_js'] = plot_js\n",
    "    # results['plot_div'] = plot_div\n",
    "    \n",
    "    # # ASSET RISKS\n",
    "    # ddf_risk = ddfs['risk']\n",
    "    # ddf_risk = ddf_risk.setHeader(col_names=['asset', 'risk', 'notes'])\n",
    "    \n",
    "    # df_risk = ddf_risk.v\n",
    "    # idx1 = getContainsIdx(df_risk, 'RISK') # find relative index of pattern\n",
    "    # idx2 = getContainsIdx(df_risk, 'CODE') # find relative index of pattern\n",
    "    # df_risk = df_risk.iloc[idx1+1:idx2,] # cut df\n",
    "    # df_risk.iloc[-2].notes += \". \" + df_risk.iloc[-1, -1]\n",
    "    # df_risk = df_risk.iloc[:-1].reset_index(drop=True)\n",
    "    # df_risk['risk'] = [1, 1, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4]\n",
    "    # df_risk['risk_word'] = df_risk['risk'].replace({1:'VERY LOW', 2: 'LOW', 3: 'MEDIUM', 4: 'HIGH'})\n",
    "    # df_risk['li_group'] = df_risk['risk'].replace({1: 'success', 2: 'info', 3: 'warning', 4: 'danger'})\n",
    "    # results['df_risk'] = df_risk # add to results\n",
    "    \n",
    "    # # ANNOUNCEMENTS\n",
    "    # df_a = ddfs['announce'].v\n",
    "    # df_a = df_a[0].str.split(pat=':', n=1, expand=True)\n",
    "    # df_a.columns = ['date', 'text']\n",
    "    # no_date_idx = df_a.index[df_a['date'].str.contains(r\"property for £980k\", case=False)][0]\n",
    "    # df_a.loc[no_date_idx, 'text'] = df_a.loc[no_date_idx, 'date']\n",
    "    # df_a.loc[no_date_idx, 'date'] = re.search(r\"[A-Z]{1}[a-z]{2}\\s202\\d{1}\", df_a.loc[no_date_idx, 'text'])[0]\n",
    "    # results['df_a'] = df_a\n",
    "    \n",
    "    # GENERAL ADVICE\n",
    "    results['df_advice'] = ddfs['advice'].v\n",
    "    \n",
    "    # GENERAL NOTES\n",
    "    df_gen = ddfs['general_notes'].v\n",
    "    df_suc = ddfs['success'].v\n",
    "\n",
    "    df_suc.iloc[0, 1] = df_suc.iloc[0, 1] + df_suc.iloc[-1,1]\n",
    "    df_gen = pd.concat([df_gen.iloc[1:], df_suc.iloc[0,:].to_frame().T]).reset_index(drop=True)\n",
    "    df_gen.columns = ['field', 'info']\n",
    "    results['df_gen'] = df_gen\n",
    "    \n",
    "    # HISTORICAL INVESTMENTS\n",
    "    df_hist = ddfs['historical'].v\n",
    "    results['df_hist'] = df_hist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example_portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddf = readXlsx('example_portf')\n",
    "metadata = getMetaDataDict(route_name='example_portf')\n",
    "\n",
    "@ioCacheAndLog(url=metadata['url'], route=metadata['route_name'], testing=True)\n",
    "def example_portf_script(ddf:DDF) -> dict:\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    ddf = ddf.setHeader(col_names=['asset', 'percent']) # set header\n",
    "    \n",
    "    # chop raw cs df into dict of 'name' : {'title':, 'df':, 'extra':}\n",
    "    mask_df = (ddf.v\n",
    "        .astype('str')\n",
    "        .apply(lambda x: x.str.startswith(\"IDEAL PORTFOLIO\", na=np.nan))\n",
    "    )\n",
    "     \n",
    "    # reference indices for separate DFs \n",
    "    ref_idxs = mask_df[mask_df.asset == True].index\n",
    "    \n",
    "    df_names = ['2023', 'crash_risk', 'high_inflation', 'normal']\n",
    "    \n",
    "    df_dict = {}\n",
    "    for i, (name, i1) in enumerate(zip(df_names, ref_idxs)):\n",
    "        i2 = None if i == len(ref_idxs)-1 else ref_idxs[i+1] - 1 \n",
    "        df_ = ddf.v.loc[i1:i2,:]\n",
    "        \n",
    "        info_dict = {}\n",
    "        info_dict['title_1'] = re.match(r\"^([^\\(]+)\\b\", df_.asset.iloc[0])[0]\n",
    "        info_dict['title_2'] = re.search(r\"(?![^\\(]+).+\", df_.asset.iloc[0])[0]\n",
    "        info_dict['df'] = df_.dropna()\n",
    "        info_dict['extra'] = df_.loc[info_dict['df'].index[-1]+1:,:].dropna(how='all').asset\n",
    "        df_dict[name] = info_dict\n",
    "        \n",
    "    df_dict['2023']['extra'].iloc[0] += ' ' + df_dict['2023']['extra'].iloc[1]\n",
    "    \n",
    "    # prepare the DFs\n",
    "    dfs = df_dict.copy()\n",
    "    \n",
    "    #return dfs['normal']['df']\n",
    "    \n",
    "    for dct in dfs.values():\n",
    "        dct['df_plot'] = dct['df'].iloc[:-1,] # strip total\n",
    "        dct['df_plot']['percent_n'] = (dct['df_plot']['percent'] * 100).astype(int) \n",
    "        dct['df_plot']['asset_hover'] = dct['df_plot']['asset'].apply(lambda x: re.match(r\"^([^\\(:]+)\", x)[0] if len(x)>35 else x)\n",
    "        dct['df'].columns = ['Asset Class', 'Percentage']\n",
    "    \n",
    "    # PLOT\n",
    "    hover_tt = f\"\"\"\n",
    "                    <div>\n",
    "                        <p style=\"margin:0;font-weight:bold;color:grey;\">@asset_hover</p>\n",
    "                        <p style=\"padding:0;margin:0;font-weight:bold;\">@percentage_hover{{0,0}}%</p>\n",
    "                    </div>\n",
    "                \"\"\"\n",
    "\n",
    "    # for dct in dfs.values():\n",
    "    #     p = pie_chart(\n",
    "    #         df=dct['df_plot'],\n",
    "    #         x='asset_hover',\n",
    "    #         y='percent_n',\n",
    "    #         x_hover='asset_hover',\n",
    "    #         percentage_decimal=0,\n",
    "    #         label_distance=3.15,\n",
    "    #         hover_tooltip=hover_tt,\n",
    "    #         legend_place='below',\n",
    "    #         fig_height=720,\n",
    "    #         radius=0.7,\n",
    "    #         background_color='#2C2B2B',\n",
    "    #         label_kwargs=dict(text_font_size='12pt', text_align='center', text_font_style='bold')\n",
    "    #     )\n",
    "    #     dct['plot_js'], dct['plot_div'] = components(p)\n",
    "        \n",
    "    return dfs\n",
    "#example_portf_script(ddf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = readXlsx('forecasts')\n",
    "metadata = getMetaDataDict(route_name='forecasts')\n",
    "\n",
    "#@ioCacheAndLog(url=metadata['url'], route=metadata['route_name'], testing=True)\n",
    "def forecasts_script(ddf:DDF) -> dict:\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # read in sub DDFs\n",
    "    ddfs = ddf.getDdfDict({\n",
    "        'forecasts' : (\"contains\", \"Forecasts\", \"down\"),\n",
    "        'risks' : (\"equals\", \"Risks\", \"down\")\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # FORECASTS\n",
    "    df_fore_styler = (ddfs['forecasts']\n",
    "        .setHeader()\n",
    "        .setStyle(keys=['color', 'font-weight'])\n",
    "        .hide(axis='index')\n",
    "    )\n",
    "    results['df_fore_styler'] = df_fore_styler\n",
    "    \n",
    "    # RISKS\n",
    "    # pallette = inferno\n",
    "    \n",
    "    ddf_risks = (ddfs['risks']\n",
    "        .setHeader()\n",
    "    )\n",
    "    df_risks = ddf_risks.v\n",
    "    df_risks['numeric_risk'] = (df_risks # convert percentage\n",
    "        .filter(regex=(r\"[Rr]isk\\s[Ll]evel.*\"))\n",
    "        .squeeze()\n",
    "        .astype('float64')\n",
    "        * 100\n",
    "    )\n",
    "    \n",
    "    df_risks = df_risks.sort_values('numeric_risk', ascending=False, ignore_index=True)\n",
    "    #df_risks['color'] = df_risks.numeric_risk.apply(riskPallette, scale=get_risk_pallete(pallette))\n",
    "    df_risks['css_ref'] = (df_risks\n",
    "        .filter(regex=(r\"[Rr]isks.*\"))\n",
    "        .squeeze()\n",
    "        .str.extract(r\"([A-Za-z0-9\\s]+)\")\n",
    "        .squeeze()\n",
    "        .str.replace('\\s', '-', regex=True)\n",
    "    )\n",
    "\n",
    "    results['df_risks'] = df_risks\n",
    "    \n",
    "    return results\n",
    "    \n",
    "#forecasts_script(ddf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddf = readXlsx('stocks')\n",
    "#metadata = getMetaDataDict(route_name='stocks')\n",
    "\n",
    "#@ioCacheAndLog(url=metadata['url'], route=metadata['route_name'], testing=True)\n",
    "def stocks_script(ddf:DDF) -> dict:\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # read in sub DDFs\n",
    "    ddfs = ddf.getDdfDict({\n",
    "        'stocks' : (\"equals\", \"Company\", \"down\"),\n",
    "        'analysis' : (\"contains\", \"Analysis ratio\", \"down\"),\n",
    "        'sectors1' : (\"contains\", \"S&P500 Index\", \"down\"),\n",
    "        'sectors2' : (\"contains\", \"Don't just buy crap! \", \"up\", 0)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    ### STOCKS TABLE ###\n",
    "    ddf_stocks = ddfs['stocks'].setHeader()\n",
    "    df_stocks = ddf_stocks.v\n",
    "    \n",
    "    # check if df is empty and if so is there extra info\n",
    "    all_nan = df_stocks.iloc[:,1:].isna().all(axis=1)\n",
    "    all_nan_idx = all_nan.loc[all_nan].index\n",
    "\n",
    "    df_stocks_info = df_stocks.loc[all_nan].dropna(axis='columns') # info\n",
    "    results['df_stocks_info'] = df_stocks_info\n",
    "    \n",
    "    df_stocks = df_stocks.loc[~df_stocks.index.isin(all_nan_idx),] # df stocks\n",
    "    results['df_stocks'] = df_stocks\n",
    "    \n",
    "    ### ANALYSIS RATIOS TABLE & TITLE ###\n",
    "    ddf_ana = ddfs['analysis']\n",
    "    df_ana = ddf_ana.v\n",
    "    \n",
    "    # title of the analysis section\n",
    "    stocks_ana_title = df_ana.iloc[0,0]\n",
    "    results['stocks_ana_title'] = stocks_ana_title\n",
    "    \n",
    "\n",
    "    # find header index\n",
    "    header_idx = df_ana.apply(lambda x: x.str.contains(r\"Ratio:\") == True).idxmax()[0] \n",
    "    header_cols = (df_ana\n",
    "        .fillna('')\n",
    "        .loc[header_idx]\n",
    "        .apply(lambda x: x.strftime(\"%b %d\") if isinstance(x, datetime.datetime) else x)\n",
    "    )\n",
    "    ddf_ana = DDF(ddf_ana.loc[header_idx+1:]).setHeader(col_names=header_cols)\n",
    "    df_ana = ddf_ana.v\n",
    "\n",
    "    df_ana.fillna('', inplace=True)\n",
    "    joined_nan_cols = df_ana.loc[:, \"\"].apply(lambda x: \"\".join(x.astype(str)), axis=1)\n",
    "    \n",
    "    # capture first nan column pos index\n",
    "    nan_col_idx = [i for i,col in enumerate(df_ana.columns) if col == \"\"][0]\n",
    "    \n",
    "    # remove original nan columns\n",
    "    ddf_ana = DDF(ddf_ana.drop([''], axis='columns'))\n",
    "    ddf_ana.insert(nan_col_idx, \"Notes\", joined_nan_cols)\n",
    "    ddf_ana['Notes'] = ddf_ana.Notes.apply(lambda x: {'value':x}) # wrap values into dict\n",
    "    df_ana_styled = (ddf_ana\n",
    "        .addButton(keys=['color', 'font-weight'], col_names=['Notes']) # add Details button\n",
    "        .setStyle(keys=['color', 'font-weight'])\n",
    "        .hide(axis='index')\n",
    "    )\n",
    "    \n",
    "    results['df_ana_styled'] = df_ana_styled\n",
    "    \n",
    "    \n",
    "    ### SUGGESTED SECTORS\n",
    "    stock_sectors_title = \"Suggested sectors for long term value\"\n",
    "    results['stock_sectors_title'] = stock_sectors_title\n",
    "    \n",
    "    ddf_sec1 = ddfs['sectors1'].setIndex(keys=0)\n",
    "    ddf_sec2 = ddfs['sectors2'].setIndex(keys=0)\n",
    "    \n",
    "    # prepare sectors 1 table\n",
    "    df_sec1 = ddf_sec1.v.apply(lambda x: x.str.strip()) # strip leading/trailing whitespaces\n",
    "    tech_label_1 = df_sec1.index[df_sec1.index.str.contains(r\"tech\", case=False, regex=True)][0]\n",
    "    df_sec1 = (df_sec1\n",
    "        .apply(lambda x: x.str.strip())\n",
    "        .apply(lambda x: x+'.' if x[-1] not in ['.', '!', '?', '%', '>'] else x, axis=\"rows\")\n",
    "        .fillna(\"\")\n",
    "        .apply(lambda x: \" \".join(x.astype(str)).strip(), axis=1)\n",
    "    )\n",
    "\n",
    "    \n",
    "    # prepare sectors 2 table\n",
    "    df_sec2 = ddf_sec2.v\n",
    "    \n",
    "    # add empty index row entry to previous\n",
    "    if df_sec2.index.isna()[-1]: \n",
    "        df_sec2.iloc[-2,-1] += ' ' + df_sec2.iloc[-1,-1]\n",
    "\n",
    "    df_sec2 = df_sec2.iloc[:-1,] # remove last row\n",
    "    tech_label_2 = df_sec2.index[df_sec2.index.str.contains(r\"tech\", case=False, regex=True)][0]\n",
    "    df_sec2 = df_sec2.rename(index={tech_label_2: tech_label_1})\n",
    "    df_sec2.columns = ['Percentage', 'Notes']\n",
    "    \n",
    "    # join and modify tables\n",
    "    df_sectors = pd.concat([df_sec1, df_sec2], axis='columns')\n",
    "    \n",
    "    df_sectors = (df_sectors\n",
    "        .drop('Percentage', axis='columns')\n",
    "        .apply(lambda x: x.str.strip())\n",
    "        .apply(lambda x: x+'.' if x[-1] not in ['.', '!', '?', '%', '>'] else x, axis=\"rows\")\n",
    "        .fillna(\"\")\n",
    "        .apply(lambda x: \" \".join(x.astype(str)).strip(), axis=1)\n",
    "    )\n",
    "\n",
    "    df_sectors = (pd.concat([df_sectors, df_sec2['Percentage']], axis='columns')\n",
    "        .rename(columns={0: 'Notes'})\n",
    "        .reset_index()\n",
    "        .rename(columns={0: 'Sector'})\n",
    "        .fillna(\"\")\n",
    "    )\n",
    "\n",
    "    df_sectors = addButton(df_sectors, col_names=['Notes'])\n",
    "    results['df_sectors'] = df_sectors # add to results\n",
    "     \n",
    "    # sectors plot\n",
    "    df_sectors_plot = df_sectors.copy()\n",
    "    df_sectors_plot['Percentage'] *= 100\n",
    "    df_sectors_plot['Percentage'] = pd.to_numeric(df_sectors['Percentage'])\n",
    "\n",
    "    # df_sectors_plot['Percentage'] = pd.to_numeric(df_sectors['Percentage'] \\\n",
    "    #     .replace(r\"%\", \"\", regex=True), errors='coerce')\n",
    "    \n",
    "    stocks_h_tooltip = f\"\"\"\n",
    "                    <div>\n",
    "                        <p style=\"margin:0;font-weight:bold;color:grey;\">@Sector</p>\n",
    "                        <p style=\"padding:0;margin:0;font-weight:bold;text-align:center;\">@percentage_hover{{0}}%</p>\n",
    "                    </div>\n",
    "                \"\"\"\n",
    "\n",
    "    # stocks_sectors_plot = donut_chart(\n",
    "    #     df=df_sectors_plot.iloc[1:,],\n",
    "    #     x='Sector',\n",
    "    #     y='Percentage',\n",
    "    #     sizing_mode='scale_both',\n",
    "    #     background_color='#2C2B2B',\n",
    "    #     percentage_decimal=0,\n",
    "    #     fig_height=90,\n",
    "    #     label_distance=3.1,\n",
    "    #     label_kwargs=dict(text_font_size='12pt', text_align='center', text_font_style='bold'),\n",
    "    #     hover_tooltip=stocks_h_tooltip,\n",
    "    #     legend_place='center',\n",
    "    #     fig_kwargs={'width':100}\n",
    "    # )\n",
    "\n",
    "    # stocks_plot_js, stocks_plot_div = components(stocks_sectors_plot)\n",
    "    # results['stocks_plot_js'] = stocks_plot_js\n",
    "    # results['stocks_plot_div'] = stocks_plot_div\n",
    "    \n",
    "    return results\n",
    "    \n",
    "#stocks_script(ddf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_stocks_info', 'df_stocks', 'stocks_ana_title', 'df_stocks_ana', 'stock_sectors_title', 'df_sectors', 'stocks_plot_js', 'stocks_plot_div'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dashboard.route.stocks import stocksScript\n",
    "from dashboard.logic.constants import nav_names\n",
    "from dashboard.logic.io import read_gsheet, getDFs, findRefRowCol, comment_button, styleDf\n",
    "\n",
    "df_dict = stocksScript()\n",
    "df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_dict = nav_names['Stocks']\n",
    "\n",
    "df_raw = read_gsheet(stocks_dict['url'], header=None)\n",
    "\n",
    "# extract data into sub DF-s\n",
    "references_dict = {\n",
    "    'stocks' : (\"equals\", \"Company\", \"down\"),\n",
    "    'analysis' : (\"contains\", \"Analysis ratio\", \"down\"),\n",
    "    'sectors1' : (\"contains\", \"S&P500 Index\", \"down\"),\n",
    "    'sectors2' : (\"contains\", \"Don't just buy crap! \", \"up\", 0)\n",
    "}\n",
    "df_dict_stocks = getDFs(df_raw, references_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Comment', 'Oct 22', 'Jan 23', 'Mar 23'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m df_ana\n\u001b[1;32m     32\u001b[0m df_ana \u001b[39m=\u001b[39m dummy()\n\u001b[0;32m---> 34\u001b[0m styleDf(df_ana, stocks_dict[\u001b[39m'\u001b[39;49m\u001b[39mroute_name\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/Documents/apps/dashboard_invest/dashboard/logic/io.py:449\u001b[0m, in \u001b[0;36mstyleDf\u001b[0;34m(df, route)\u001b[0m\n\u001b[1;32m    447\u001b[0m df_style_dict \u001b[39m=\u001b[39m df_style_dict\u001b[39m.\u001b[39miloc[\u001b[39m1\u001b[39m:,]\n\u001b[1;32m    448\u001b[0m df_style_dict\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m df_style_dict_cols\n\u001b[0;32m--> 449\u001b[0m df_style_dict \u001b[39m=\u001b[39m df_style_dict\u001b[39m.\u001b[39;49mloc[:, df\u001b[39m.\u001b[39;49mcolumns] \u001b[39m# get original rows & cols\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m# check if respective DFs match\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39massert\u001b[39;00m df\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m df_style_dict\u001b[39m.\u001b[39mshape, \u001b[39m\"\u001b[39m\u001b[39mProvided DF and Excel Table have different shape.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dashboard_invest-5AWLHTjn/lib/python3.11/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dashboard_invest-5AWLHTjn/lib/python3.11/site-packages/pandas/core/indexing.py:1256\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m   1254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[0;32m-> 1256\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dashboard_invest-5AWLHTjn/lib/python3.11/site-packages/pandas/core/indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    922\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    925\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dashboard_invest-5AWLHTjn/lib/python3.11/site-packages/pandas/core/indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1299\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1303\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dashboard_invest-5AWLHTjn/lib/python3.11/site-packages/pandas/core/indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1238\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dashboard_invest-5AWLHTjn/lib/python3.11/site-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1430\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1432\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1434\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dashboard_invest-5AWLHTjn/lib/python3.11/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dashboard_invest-5AWLHTjn/lib/python3.11/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Comment', 'Oct 22', 'Jan 23', 'Mar 23'] not in index\""
     ]
    }
   ],
   "source": [
    "def dummy():\n",
    "\n",
    "    ### ANALYSIS RATIOS TABLE & TITLE ###\n",
    "    df_ana = df_dict_stocks['analysis'].copy()\n",
    "\n",
    "    # title of the analysis section\n",
    "    stocks_ana_title = df_ana.iloc[0,0]\n",
    "\n",
    "    # set header\n",
    "    header_idx = findRefRowCol(df_ana.astype('str'), r\"Ratio:\", 'contains')[0]\n",
    "    \n",
    "    df_ana.columns = df_ana.loc[header_idx]\n",
    "    df_ana = df_ana.loc[header_idx+1:]\n",
    "    df_ana.columns = df_ana.columns.fillna('') # fill NaN headers \"\"\n",
    "        \n",
    "    # Join column values using whitespace for columns with NaN header\n",
    "    df_ana = df_ana.fillna('')\n",
    "    joined_nan_cols = df_ana.loc[:, \"\"].apply(lambda x: \"\".join(x.astype(str)), axis=1)\n",
    "\n",
    "    # capture first nan column pos index\n",
    "    nan_col_idx = [i for i,col in enumerate(df_ana.columns) if col == \"\"][0]\n",
    "\n",
    "    # remove original nan columns\n",
    "    df_ana = df_ana.drop([''], axis='columns')\n",
    "    df_ana.insert(nan_col_idx, \"Comment\", joined_nan_cols)\n",
    "\n",
    "    # add comment button \n",
    "    df_ana.Comment[df_ana.Comment != ''] = df_ana.Comment[df_ana.Comment != ''].apply(comment_button)\n",
    "\n",
    "    return df_ana\n",
    "    \n",
    "df_ana = dummy()\n",
    "\n",
    "styleDf(df_ana, stocks_dict['route_name'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CACHING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Workbook as .xlsx with timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dashboard.logic.constants import nav_names\n",
    "from dashboard.logic.io import *\n",
    "\n",
    "#dct = nav_names['2023 Forecasts & Risks']\n",
    "dct = nav_names['Investment Allocation Examples']\n",
    "\n",
    "\n",
    "path = \"/home/tonu/Documents/apps/dashboard_invest/dashboard/cache/example_portf\"\n",
    "df = read_gsheet(, header=None)\n",
    "mask_df = df.apply(lambda x: x.str.startswith(\"IDEAL PORTFOLIO\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new name', 'page', 'route_name', 'symbol_id', 'title', 'url'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key for key in dct if key != 'routes'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import os\n",
    "import traceback\n",
    "import re\n",
    "\n",
    "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/15-kxhuk4h1BdFuiSIueamEifJpjsG6Loi621KQ8hGuY/edit#gid\"\n",
    "\n",
    "\n",
    "def getTimestamp(format: str=\"%Y-%m-%d_%H:%M:%S\") -> str:\n",
    "    \"\"\"Generate a timestamp string in the format YYYY-MM-DD_HH:MM:SS\"\"\" \n",
    "    return datetime.datetime.now().strftime(format)\n",
    "\n",
    "def getOldestFilename(files: list[str], ts_format:str=\"%Y-%m-%d_%H:%M:%S\") -> str:\n",
    "    \"\"\"Returns the filename with oldest timestamp\"\"\"\n",
    "    ts_pattern = r\"\\d[\\d\\-_:]+\\d\"\n",
    "    return min(files, key=lambda x: datetime.datetime.strptime(re.search(ts_pattern, x)[0][:19], ts_format))\n",
    "\n",
    "def getNewestFilename(files: list[str], ts_format:str=\"%Y-%m-%d_%H:%M:%S\") -> str:\n",
    "    \"\"\"Returns the filename with newest timestamp\"\"\"\n",
    "    ts_pattern = r\"\\d[\\d\\-_:]+\\d\"\n",
    "    return max(files, key=lambda x: datetime.datetime.strptime(re.search(ts_pattern, x)[0][:19], ts_format))\n",
    "\n",
    "def downloadWorkbook(spreadsheet_url: str, \n",
    "                     file_path: str,\n",
    "                     file_name: str='workbook') -> None:\n",
    "    \"\"\"Download Google Spreadsheet as an .xlsx file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the file name and extension\n",
    "    file_ext = \".xlsx\"\n",
    "\n",
    "    # Generate a timestamp string in the format YYYY-MM-DD_HH-MM-SS\n",
    "    timestamp = getTimestamp()\n",
    "\n",
    "    # Concatenate the timestamp string with the file name and extension\n",
    "    timestamped_file_name = f\"{file_path}/{timestamp}_{file_name}{file_ext}\"\n",
    "\n",
    "    # SAVE GOOGLE SPREADSHEET AS .XLSX FILE\n",
    "    export_url = spreadsheet_url.replace(\"edit#gid\", \"export?format=xlsx\")\n",
    "\n",
    "    response = requests.get(export_url)\n",
    "\n",
    "    with open(timestamped_file_name, \"wb\") as output_file:\n",
    "        output_file.write(response.content)\n",
    "        \n",
    "\n",
    "def downloadSheet(spreadsheet_url: str, \n",
    "                  file_path: str,\n",
    "                  file_name: str) -> None:\n",
    "    \"\"\"Download Google Spreadsheet as an .xlsx file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the file name and extension\n",
    "    file_ext = \".xlsx\"\n",
    "\n",
    "    # Generate a timestamp string in the format YYYY-MM-DD_HH-MM-SS\n",
    "    timestamp = getTimestamp()\n",
    "\n",
    "    # Concatenate the timestamp string with the file name and extension\n",
    "    timestamped_file_name = f\"{file_path}/{timestamp}_{file_name}{file_ext}\"\n",
    "\n",
    "    # SAVE GOOGLE SPREADSHEET AS .XLSX FILE\n",
    "    download_url = spreadsheet_url.replace('/edit#','/export?format=xlsx&')\n",
    "\n",
    "    response = requests.get(download_url)\n",
    "\n",
    "    with open(timestamped_file_name, \"wb\") as output_file:\n",
    "        output_file.write(response.content)\n",
    "\n",
    "\n",
    "def logError(route:str, exception:Exception) -> None:\n",
    "    \"\"\"Save occurred error traceback to file with timestamp.\"\"\"\n",
    "    \n",
    "    log_path = f\"dashboard/logs/routes/{route}\"\n",
    "    if not os.path.exists(log_path):\n",
    "        os.mkdir(log_path)\n",
    "    \n",
    "    files = os.listdir(log_path)\n",
    "    if len(files) >= 10:\n",
    "        oldest_file = getOldestFilename(files=files)\n",
    "        os.remove(os.path.join(log_path, oldest_file))\n",
    "        \n",
    "    error_name = exception.__class__.__name__\n",
    "    \n",
    "    with open(f'{log_path}/{getTimestamp()}_{error_name}', 'a') as f: \n",
    "        traceback.print_exc(file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cryptocurrencies'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# native imports\n",
    "from functools import wraps\n",
    "\n",
    "# local imports\n",
    "from dashboard.logic.io import read_gsheet\n",
    "from dashboard.logic.constants import GSHEETS_URL\n",
    "\n",
    "# 3rd party imports\n",
    "import pandas as pd\n",
    "\n",
    "xlsx_test_path = \"dashboard/cache/main_backup/workbook_2023-03-10_17-11-59.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "def ioCacheAndLog(\n",
    "    route: str,\n",
    "    gsheet_dict:dict=None, \n",
    "    excel_dict:dict=None):\n",
    "    \n",
    "    def my_decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            # try reading data from google sheets\n",
    "            try:\n",
    "                io = gsheet_dict['io']\n",
    "                del gsheet_dict['io']\n",
    "                df = read_gsheet(io, **gsheet_dict)\n",
    "                result = func(df)\n",
    "                \n",
    "                # download spreadsheet to cache\n",
    "                cache_path = os.path.join('dashboard', 'cache', route)\n",
    "                if not os.path.exists(cache_path):\n",
    "                    os.mkdir(cache_path)\n",
    "                    \n",
    "                # don't save more than 3 files to cache\n",
    "                files = os.listdir(cache_path)\n",
    "                if len(files) >= 3:\n",
    "                    oldest_file = getOldestFilename(files=files)\n",
    "                    os.remove(os.path.join(cache_path, oldest_file))\n",
    "                \n",
    "                # download google sheet as .xlsx file\n",
    "                downloadSheet(spreadsheet_url=io, \n",
    "                              file_path=cache_path,\n",
    "                              file_name=route)\n",
    "                return result\n",
    "            \n",
    "            # read data from cache\n",
    "            except Exception as e:\n",
    "                # capture and save occurred error log\n",
    "                logError(route=route, exception=e)\n",
    "                \n",
    "                # read data from the newest cached file\n",
    "                io_cache_path = os.path.join('dashboard', 'cache', route)\n",
    "                newest_file_name = getNewestFilename(os.listdir(io_cache_path))\n",
    "                df  = read_excel(os.path.join(io_cache_path, newest_file_name), **excel_dict)\n",
    "                \n",
    "                result = func(df)\n",
    "                return result\n",
    "        return wrapper\n",
    "    \n",
    "    return my_decorator\n",
    "\n",
    "dict1 = dict(io=GSHEETS_URL, header=None)\n",
    "dict2 = dict(sheet_name='Investments', header=None)\n",
    "\n",
    "@ioCacheAndLog(route='investments', gsheet_dict=dict1, excel_dict=dict2)\n",
    "def test_script(df):\n",
    "    return df.iloc[0,0]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My Finance Course',\n",
       " 'My UK Property Courses',\n",
       " 'Private 1-on-1 Sessions With',\n",
       " 'Where I Buy Allocated',\n",
       " 'Where I Buy Physical',\n",
       " 'How I Protect My',\n",
       " 'The Stock Platform I',\n",
       " 'A Global bank account']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_gsheet(nav_names['Investments']['url'], header=None)\n",
    "# Extract sub DF to dictionary\n",
    "references_dict = {\n",
    "    'main' : (\"contains\", \"Monthly Income\", 'up'),\n",
    "    'ads' : (\"contains\", 'My Finance Course', 'down'),\n",
    "    'announce' : (\"contains\", \"Jul 2022: I'm\", 'up'),\n",
    "    'advice' : (\"contains\", '3x Excellent', 'up'),\n",
    "    'warning_msg' : (\"contains\", 'NOTE: Occasionally', 'one'),\n",
    "    'risk' : (\"equals\", \"RISK\", 'down', 0),\n",
    "    'historical' : (\"equals\", \"My Historical Investments\", \"down\"),\n",
    "    'cash_pos' : (\"contains\", \"CASH POSITION\", 'one'),\n",
    "    'general_notes' : (\"equals\", \"GENERAL NOTES\", \"down\"),\n",
    "    'success' : (\"equals\", \"Investment Success:\", \"down\")\n",
    "}\n",
    "\n",
    "df_dict = getDFs(df, references_dict=references_dict)\n",
    "\n",
    "# ADS\n",
    "df_ads = df_dict['ads'].copy()\n",
    "df_ads.columns = ['text', 'hyperlink']\n",
    "df_ads['icon'] = df_ads.text.str.extract(r\"\\s*(\\S)\")\n",
    "df_ads['text'] = df_ads.text.str.extract(r\"(\\b.+[^\\s])\")\n",
    "\n",
    "# headers = ['My Finance Course', 'My UK Property Courses', 'Mentoring', 'Metals Globally', \n",
    "#         'Metals USA', 'Metals UK', 'Crypto Security', 'Stock Platform', 'Bank Account']\n",
    "\n",
    "headers = [\" \".join(string.split()[:4]) for string in df_ads['text']]\n",
    "headers\n",
    "# icons_html_dict = {'My Finance Course' : 'bi bi-graph-up-arrow', \n",
    "#                     'My UK Property Courses' : 'bi bi-house', \n",
    "#                     'Mentoring' : 'fa-regular fa-handshake', \n",
    "#                     'Metals Globally': 'bi bi-globe-asia-australia', \n",
    "#                     'Metals USA': 'bi bi-currency-dollar', \n",
    "#                     'Metals UK': 'bi bi-currency-pound', \n",
    "#                     'Crypto Security': 'bi bi-currency-bitcoin', \n",
    "#                     'Stock Platform': 'fa-solid fa-chart-column', \n",
    "#                     'Bank Account': 'bi bi-bank'}\n",
    "\n",
    "# df_ads['header'] = headers\n",
    "# df_ads['new_icon_html'] = df_ads['header'].map(icons_html_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bg_color(val, cmap: dict) -> str:\n",
    "    \"\"\"Map colors to DF values based on mapping dictionary.\n",
    "\n",
    "    Args:\n",
    "        val ( any type): Any value type.\n",
    "        cmap (dict): Dict of the form {val:'color'}\n",
    "    \"\"\"\n",
    "    return f'background-color: {cmap[val]}'\n",
    "\n",
    "cmap = {i:c for i,c in zip(df_risks['Risk Level in 2023'], df_risks['color'])}\n",
    "\n",
    "\n",
    "\n",
    "# print((df_risks.style\n",
    "#     .applymap(set_bg_color, cmap=cmap, subset=['Risk Level in 2023'])\n",
    "#     .set_properties(subset=pd.IndexSlice[4,'Risk Level in 2023'], **{\"border-top-right-radius\": \"0.6em\"})\n",
    "#     .hide(axis='index')\n",
    "# ).to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>16</th>\n",
       "      <th>Risks</th>\n",
       "      <th>Risk Level in 2023</th>\n",
       "      <th>numeric_risk</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recession</td>\n",
       "      <td>90%</td>\n",
       "      <td>90.0</td>\n",
       "      <td>#000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stock Market Crash 40%+</td>\n",
       "      <td>65%</td>\n",
       "      <td>65.0</td>\n",
       "      <td>#781C6D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cyber Pandemic</td>\n",
       "      <td>50%</td>\n",
       "      <td>50.0</td>\n",
       "      <td>#A42C60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Housing Crash 20%+</td>\n",
       "      <td>35%</td>\n",
       "      <td>35.0</td>\n",
       "      <td>#ED6825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bank Bail Ins</td>\n",
       "      <td>30%</td>\n",
       "      <td>30.0</td>\n",
       "      <td>#ED6825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "16                    Risks Risk Level in 2023  numeric_risk    color\n",
       "0                 Recession                90%          90.0  #000003\n",
       "1   Stock Market Crash 40%+                65%          65.0  #781C6D\n",
       "2            Cyber Pandemic                50%          50.0  #A42C60\n",
       "3        Housing Crash 20%+                35%          35.0  #ED6825\n",
       "4             Bank Bail Ins                30%          30.0  #ED6825"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dashboard.logic.constants import nav_names\n",
    "from dashboard.logic.io import read_gsheet, getDFs\n",
    "from bokeh.palettes import inferno\n",
    "\n",
    "def riskPallette(series: pd.Series, scale: dict) -> pd.Series:\n",
    "    \"\"\"Apply color based on risk level (# between 0-100).\n",
    "\n",
    "    Args:\n",
    "        scale (dict): Dictionary of the form {0:color, ... , 9:color}\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: color\n",
    "    \"\"\"\n",
    "    if series >= 90: \n",
    "        return scale[\"9\"]\n",
    "    if series < 10: \n",
    "        return scale[\"0\"]\n",
    "    else: \n",
    "        return scale[str(series)[0]]\n",
    "\n",
    "def get_risk_pallete(pallette: dict) -> dict['int':'color']:\n",
    "    \"\"\"Generate risk pallete in scale 0 to 100 in steps of 10.\n",
    "    Args:\n",
    "        pallette (dict): Dictionary {n: ['colors'....]}\n",
    "    Returns:\n",
    "        Dict: Dictionary {\"0\": 'color'}\n",
    "    \"\"\"\n",
    "    return {str(i):color for i,color in enumerate(pallette(10)[::-1])}\n",
    "\n",
    "FORECASTS_URL = nav_names['2023 Forecasts & Risks']['url']\n",
    "\n",
    "# read spreadsheet in as DF\n",
    "df_fore_raw = read_gsheet(url=FORECASTS_URL, header=None)\n",
    "\n",
    "# extract data into sub DF-s\n",
    "references_dict = {\n",
    "    'forecasts' : (\"contains\", \"Forecasts\", \"down\"),\n",
    "    'risks' : (\"equals\", \"Risks\", \"down\")\n",
    "}\n",
    "df_dict_fore = getDFs(df_fore_raw, references_dict)\n",
    "\n",
    "# FORECASTS\n",
    "df_fore = df_dict_fore['forecasts'].copy()\n",
    "df_fore.columns = df_fore.iloc[0]\n",
    "df_fore = df_fore.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "# RISKS\n",
    "risks_scale = {str(i):color for i,color in enumerate(inferno(10)[::-1])}\n",
    "\n",
    "df_risks = df_dict_fore['risks'].copy()\n",
    "df_risks.columns = df_risks.iloc[0]\n",
    "df_risks = df_risks.iloc[1:].reset_index(drop=True)\n",
    "df_risks['numeric_risk'] = (df_risks\n",
    "    .filter(regex=(r\"[Rr]isk\\s[Ll]evel.*\"))\n",
    "    .squeeze()\n",
    "    .str.extract(r\"(\\d+)\")\n",
    "    .astype('float64')\n",
    ")\n",
    "df_risks = df_risks.sort_values('numeric_risk', ascending=False, ignore_index=True)\n",
    "df_risks['color'] = df_risks.numeric_risk.apply(riskPallette, scale=get_risk_pallete(inferno))\n",
    "\n",
    "\n",
    "df_risks\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRefRowCol(df: pd.DataFrame, pattern: str, method: str='contains') -> tuple[int, int]:\n",
    "    \"\"\"Find reference row and column numeric index values.\n",
    "\n",
    "    Args:\n",
    "        pattern (str): Character sequence or regular expression.\n",
    "        method (str, optional): Finding reference via pattern within the text ('contains')\n",
    "            or equalling the value exactly ('equals'). Defaults to 'contains'.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Raises error if other than ['contains', 'equals'] is specified for the method.\n",
    "\n",
    "    Returns:\n",
    "        tuple[int, int]: Tuple of ['row_i', 'col_i']\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # validate that method is correctly entered\n",
    "    if method not in ['contains', 'equals']:\n",
    "        raise ValueError(f\"{method} can take only values: 'contains' or 'equals'!\")\n",
    "    \n",
    "    idx_series = None\n",
    "    if method == 'contains':\n",
    "        idx_series = df.apply(lambda x: x.str.contains(pattern)).idxmax()\n",
    "    if method == 'equals':\n",
    "        idx_series = (df == pattern).idxmax()\n",
    "    \n",
    "    return idx_series.max(), idx_series.idxmax() \n",
    "    \n",
    "def sliceDF(df: pd.DataFrame, \n",
    "            row_idx1: int=None, \n",
    "            row_idx2:int=None, \n",
    "            col_idx1: int=None, \n",
    "            col_idx2: int=None,\n",
    "            col_0: bool=True, \n",
    "            direction='down') -> pd.DataFrame:\n",
    "    \"\"\"Slice DF till the first occuring empty row in given direction.\n",
    "\n",
    "    Args:\n",
    "        col_0 (bool, optional): If col_idx1 is actually first column. Defaults to True.\n",
    "        direction (str, optional): Slice upwards or downwards from given row index. Defaults to 'down'.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no row indices are specified.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # assert that at least one of the row indices is specified\n",
    "    if row_idx1 is None and row_idx2 is None:\n",
    "        raise ValueError(f\"Both row indices can't equal {None}!\") \n",
    "    \n",
    "    # if column index is not the first column then None\n",
    "    col_idx1 = col_idx1 if col_0 is True else None\n",
    "    \n",
    "    # find missing row index\n",
    "    if direction == 'down':\n",
    "        nan_mask = (df.iloc[row_idx1:,col_idx1:col_idx2] == 'nan').all(axis='columns')\n",
    "        row_idx2 = None if nan_mask.sum() == 0 else nan_mask.idxmax()\n",
    "        \n",
    "    \n",
    "    if direction == 'up':\n",
    "        nan_mask = (df.iloc[:row_idx2,col_idx1:col_idx2] == 'nan').all(axis='columns')\n",
    "        row_idx1 = None if nan_mask.sum() == 0 else nan_mask[::-1].idxmax() + 1\n",
    "        row_idx2 += 1\n",
    "         \n",
    "    return df.iloc[row_idx1:row_idx2,col_idx1:col_idx2]\n",
    "\n",
    "def getDFs(df: pd.DataFrame, references_dict: dict[str, tuple[str,str,str]]) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"Get subset DFs from a bigger DF based on reference strings.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Raw initial DF.\n",
    "        references_dict (dict): Dictionary of df_name: tuple('method', 'string' , 'direction', int('col_idx1)).\n",
    "            method has 2 options ['contains' and 'equals'], 'direction' has 3 options \n",
    "            ['one', 'down', 'up'] where one means only one line needs to be parsed, 'up' and 'down'\n",
    "            respectively correspond to the parsing direction from the reference point.\n",
    "            \n",
    "            Returns:\n",
    "        dict: Dictionary of {'df_name': df}\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # set all cols str type, NaN -> 'nan'\n",
    "    df = df.reset_index(drop=True).astype(str)\n",
    "    \n",
    "    # find reference indices\n",
    "    dfs = {}\n",
    "    for k,v in references_dict.items():\n",
    "        \n",
    "        # find ref position\n",
    "        row_i, col_i = findRefRowCol(df, pattern=v[1], method=v[0])\n",
    "        \n",
    "        # shift ref position if specified\n",
    "        col_i = v[3] if len(v) == 4 else col_i\n",
    "        \n",
    "        if v[2] == 'one':\n",
    "            dfs[k] = df.iloc[row_i,col_i:]\n",
    "        if v[2] == 'down':\n",
    "            dfs[k] = sliceDF(df, row_idx1=row_i, col_idx1=col_i, direction=v[2])\n",
    "        if v[2] == 'up':\n",
    "            dfs[k] = sliceDF(df, row_idx2=row_i, col_idx1=col_i, direction=v[2])\n",
    "\n",
    "    # strip all NaN cols and rows\n",
    "    dfs_clean = {}\n",
    "    for k,df_ in dfs.items():\n",
    "        \n",
    "        if isinstance(df_, pd.Series):\n",
    "            dfs_clean[k] = (df_\n",
    "            .replace({'nan': np.nan})\n",
    "            .dropna(how='any', axis='rows')\n",
    "            )\n",
    "        else:\n",
    "            dfs_clean[k] = (df_\n",
    "                .replace({'nan': np.nan})\n",
    "                .dropna(how='all', axis='columns')\n",
    "                .dropna(how='all', axis='rows')\n",
    "            )\n",
    "    \n",
    "    return dfs_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['stocks', 'analysis', 'sectors1', 'sectors2'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dashboard.logic.constants import nav_names\n",
    "from dashboard.logic.io import read_gsheet\n",
    "\n",
    "STOCKS_URL = nav_names['Stocks']['url']\n",
    "\n",
    "# read spreadsheet in as DF\n",
    "df_stocks_raw = read_gsheet(url=STOCKS_URL, header=None)\n",
    "\n",
    "# extract data into sub DF-s\n",
    "references_dict = {\n",
    "    'stocks' : (\"equals\", \"Company\", \"down\"),\n",
    "    'analysis' : (\"contains\", \"Analysis ratio\", \"down\"),\n",
    "    'sectors1' : (\"contains\", \"S&P500 Index\", \"down\"),\n",
    "    'sectors2' : (\"contains\", \"Don't just buy crap! \", \"up\", 0)\n",
    "}\n",
    "df_dict_stocks = getDFs(df_stocks_raw, references_dict)\n",
    "\n",
    "df_dict_stocks.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The absolute easiest strategy for stock market...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Start looking to move away from (Growth &amp; Tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Usually for a super safe play, I would suggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I would suggest that since market growth is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>...reverse course, they will go back to QE &amp; l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   The absolute easiest strategy for stock market...\n",
       "2   Start looking to move away from (Growth & Tech...\n",
       "15  Usually for a super safe play, I would suggest...\n",
       "16  I would suggest that since market growth is no...\n",
       "17  ...reverse course, they will go back to QE & l..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getNonSelectedDF(\n",
    "    df_raw: pd.DataFrame, \n",
    "    df_dict: dict['df_name': pd.DataFrame], \n",
    "    start_idx: int=0, \n",
    "    stop_idx: int=None) -> pd.DataFrame:\n",
    "    \"\"\"Get data into DF that wasn't captured based on negative df_dict. \n",
    "\n",
    "    Args:\n",
    "        df_raw (pd.DataFrame): Original DF where data wasn't cpatured.\n",
    "        df_dict (_type_): Dict of the form {subdf_name: 'method', 'string' , 'direction', int('col_idx1))}.\n",
    "        start_idx (int, optional): Starting row index (not positional).\n",
    "        stop_idx (int, optional): Ending row index (not positional).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DF with rest of the info captured and NaN rows/cols stripped.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # find indicies already capture by \"getDFs\" function\n",
    "    indices = np.array([])\n",
    "    for df_ in df_dict.values():\n",
    "        indices = np.concatenate((indices, df_.index.values))\n",
    "    indices = [int(i) for i in indices]\n",
    "    \n",
    "    # subset DF\n",
    "    df_sub = (df_raw\n",
    "        .loc[~df_stocks_raw.index.isin(indices),:]\n",
    "        .loc[start_idx:stop_idx,]\n",
    "        .dropna(axis='columns', how='all')\n",
    "        .dropna(axis='rows', how='all')\n",
    "    )\n",
    "    \n",
    "    return df_sub\n",
    "    \n",
    "    \n",
    "getNonSelectedDF(df_stocks_raw, df_dict_stocks, stop_idx=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STOCKS TABLE ###\n",
    "df_stocks = df_dict_stocks['stocks'].copy().reset_index(drop=True)\n",
    "\n",
    "# set column headers\n",
    "df_stocks.columns = df_stocks.iloc[0]\n",
    "df_stocks = df_stocks.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "# check if df is empty and if so is there extra info\n",
    "all_nan = df_stocks.iloc[:,1:].isna().all(axis=1)\n",
    "all_nan_idx = all_nan.loc[all_nan].index\n",
    "\n",
    "\n",
    "df_stocks_info = df_stocks.loc[all_nan].dropna(axis='columns') # info\n",
    "df_stocks = df_stocks.loc[~df_stocks.index.isin(all_nan_idx),] # df stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>8</th>\n",
       "      <th>Ratio:</th>\n",
       "      <th>Average</th>\n",
       "      <th>Current</th>\n",
       "      <th>Value?</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Oct 22</th>\n",
       "      <th>Sep 22</th>\n",
       "      <th>Jan 23</th>\n",
       "      <th>Feb 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S&amp;P 500 (P/E)</td>\n",
       "      <td>15</td>\n",
       "      <td>19.97</td>\n",
       "      <td>Overvalued</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.00</td>\n",
       "      <td>19.97</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shiller P/E</td>\n",
       "      <td>16</td>\n",
       "      <td>28.09</td>\n",
       "      <td>Overvalued</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>29.4</td>\n",
       "      <td>31.00</td>\n",
       "      <td>28.09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S&amp;P Price to Book</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.83</td>\n",
       "      <td>Overvalued</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.10</td>\n",
       "      <td>3.83</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S&amp;P Price to Sales</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.31</td>\n",
       "      <td>Overvalued</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.31</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S&amp;P Dividend Yield</td>\n",
       "      <td>5.0%</td>\n",
       "      <td>5.0%</td>\n",
       "      <td>Fair</td>\n",
       "      <td></td>\n",
       "      <td>4.9%</td>\n",
       "      <td>4.8%</td>\n",
       "      <td>5.0%</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "8              Ratio: Average Current      Value?  \\\n",
       "0       S&P 500 (P/E)      15   19.97  Overvalued   \n",
       "1         Shiller P/E      16   28.09  Overvalued   \n",
       "2   S&P Price to Book     2.9    3.83  Overvalued   \n",
       "3  S&P Price to Sales     1.6    2.31  Overvalued   \n",
       "4  S&P Dividend Yield    5.0%    5.0%        Fair   \n",
       "\n",
       "8                                            Comment Oct 22 Sep 22 Jan 23  \\\n",
       "0  <button type=\"button\" class=\"btn btn-secondary...   20.7  21.00  19.97   \n",
       "1  <button type=\"button\" class=\"btn btn-secondary...   29.4  31.00  28.09   \n",
       "2  <button type=\"button\" class=\"btn btn-secondary...   3.98   4.10   3.83   \n",
       "3  <button type=\"button\" class=\"btn btn-secondary...   2.45   2.60   2.31   \n",
       "4                                                      4.9%   4.8%   5.0%   \n",
       "\n",
       "8 Feb 23  \n",
       "0         \n",
       "1         \n",
       "2         \n",
       "3         \n",
       "4         "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dashboard.logic.io import comment_button\n",
    "\n",
    "df_ana = df_dict_stocks['analysis'].copy()\n",
    "\n",
    "# title of the analysis section\n",
    "ana_title = df_ana.iloc[0,0]\n",
    "\n",
    "# set header\n",
    "header_idx = findRefRowCol(df_ana.astype('str'), r\"Ratio:\", 'contains')[0]\n",
    "df_ana.columns = df_ana.loc[header_idx]\n",
    "df_ana = df_ana.loc[header_idx+1:].reset_index(drop=True)\n",
    "df_ana.columns = df_ana.columns.fillna('') # fill NaN headers \"\"\n",
    "\n",
    "# Join column values using whitespace for columns with NaN header\n",
    "df_ana = df_ana.fillna('')\n",
    "joined_nan_cols = df_ana.loc[:, \"\"].apply(lambda x: \"\".join(x.astype(str)), axis=1)\n",
    "\n",
    "# capture first nan column pos index\n",
    "nan_col_idx = [i for i,col in enumerate(df_ana.columns) if col == \"\"][0]\n",
    "\n",
    "# remove original nan columns\n",
    "df_ana = df_ana.drop([''], axis='columns')\n",
    "df_ana.insert(nan_col_idx, \"Comment\", joined_nan_cols)\n",
    "\n",
    "# add comment button \n",
    "df_ana.Comment[df_ana.Comment != ''] = df_ana.Comment[df_ana.Comment != ''].apply(comment_button)\n",
    "df_ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1: S&amp;P500 Index</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENERGY</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MINING</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGRICULTURE</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEAP TECH</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sector                                            Comment  \\\n",
       "0  #1: S&P500 Index  <button type=\"button\" class=\"btn btn-secondary...   \n",
       "1            ENERGY  <button type=\"button\" class=\"btn btn-secondary...   \n",
       "2            MINING  <button type=\"button\" class=\"btn btn-secondary...   \n",
       "3       AGRICULTURE  <button type=\"button\" class=\"btn btn-secondary...   \n",
       "4        CHEAP TECH  <button type=\"button\" class=\"btn btn-secondary...   \n",
       "\n",
       "  Proportion  \n",
       "0             \n",
       "1        30%  \n",
       "2        30%  \n",
       "3        20%  \n",
       "4        20%  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Suggested Sectors\n",
    "df_sec1 = df_dict_stocks['sectors1'].copy().set_index(0)\n",
    "df_sec2 = df_dict_stocks['sectors2'].copy().set_index(0)\n",
    "\n",
    "# prepare sectors 1 table\n",
    "df_sec1 = df_sec1 = df_sec1.apply(lambda x: x.str.strip())\n",
    "tech_label_1 = df_sec1.index[df_sec1.index.str.contains(r\"tech\", case=False, regex=True)][0]\n",
    "\n",
    "df_sec1 = (df_sec1\n",
    "    .apply(lambda x: x.str.strip())\n",
    "    .apply(lambda x: x+'.' if x[-1] not in ['.', '!', '?', '%', '>'] else x, axis=\"rows\")\n",
    "    .fillna(\"\")\n",
    "    .apply(lambda x: \" \".join(x.astype(str)).strip(), axis=1)\n",
    ")\n",
    "\n",
    "# add empty index row entry to previous\n",
    "if df_sec2.index.isna()[-1]:\n",
    "    df_sec2.iloc[-2,-1] += ' ' + df_sec2.iloc[-1,-1]\n",
    "\n",
    "# prepare sectors 2 table\n",
    "df_sec2 = df_sec2.iloc[:-1,] # remove last row\n",
    "tech_label_2 = df_sec2.index[df_sec2.index.str.contains(r\"tech\", case=False, regex=True)][0]\n",
    "df_sec2 = df_sec2.rename(index={tech_label_2: tech_label_1})\n",
    "df_sec2.columns = ['Proportion', 'Comment']\n",
    "\n",
    "# join and modify tables\n",
    "df_sectors = pd.concat([df_sec1, df_sec2], axis='columns')\n",
    "\n",
    "df_sectors = (df_sectors\n",
    "    .drop('Proportion', axis='columns')\n",
    "    .apply(lambda x: x.str.strip())\n",
    "    .apply(lambda x: x+'.' if x[-1] not in ['.', '!', '?', '%', '>'] else x, axis=\"rows\")\n",
    "    .fillna(\"\")\n",
    "    .apply(lambda x: \" \".join(x.astype(str)).strip(), axis=1)\n",
    ")\n",
    "\n",
    "df_sectors = (pd.concat([df_sectors, df_sec2['Proportion']], axis='columns')\n",
    "    .rename(columns={0: 'Comment'})\n",
    "    .reset_index()\n",
    "    .rename(columns={0: 'Sector'})\n",
    "    .fillna(\"\")\n",
    ")\n",
    "\n",
    "\n",
    "df_sectors.Comment[df_sectors.Comment != ''] = \\\n",
    "    df_sectors.Comment[df_sectors.Comment != ''].apply(comment_button)\n",
    "    \n",
    "df_sectors\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# bokeh\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, Legend, LabelSet, LegendItem, HoverTool, AnnularWedge\n",
    "from bokeh.layouts import column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"p2777\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"p2777\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.0.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.0.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.0.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.0.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.0.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"p2777\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1: S&amp;P500 Index</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENERGY</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MINING</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGRICULTURE</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEAP TECH</td>\n",
       "      <td>&lt;button type=\"button\" class=\"btn btn-secondary...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sector                                            Comment  \\\n",
       "0  #1: S&P500 Index  <button type=\"button\" class=\"btn btn-secondary...   \n",
       "1            ENERGY  <button type=\"button\" class=\"btn btn-secondary...   \n",
       "2            MINING  <button type=\"button\" class=\"btn btn-secondary...   \n",
       "3       AGRICULTURE  <button type=\"button\" class=\"btn btn-secondary...   \n",
       "4        CHEAP TECH  <button type=\"button\" class=\"btn btn-secondary...   \n",
       "\n",
       "   Proportion  \n",
       "0         NaN  \n",
       "1        30.0  \n",
       "2        30.0  \n",
       "3        20.0  \n",
       "4        20.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sectors_plot = df_sectors.copy()\n",
    "df_sectors_plot['Proportion'] = pd.to_numeric(df_sectors['Proportion'].replace(r\"%\", \"\", regex=True),\n",
    "    errors='coerce')\n",
    "\n",
    "df_sectors_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"66a189bc-2864-424e-ba86-d3f23408f3f4\" data-root-id=\"p43740\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"8cd6973e-7b00-476d-a99c-04227123fb13\":{\"version\":\"3.0.3\",\"title\":\"Bokeh Application\",\"defs\":[],\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p43740\",\"attributes\":{\"width\":500,\"height\":500,\"sizing_mode\":\"fixed\",\"x_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p43749\",\"attributes\":{\"start\":-1}},\"y_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p43751\",\"attributes\":{\"start\":-1.0}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p43753\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p43755\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p43748\"},\"outline_line_color\":\"#2C2B2B\",\"outline_line_alpha\":0,\"outline_line_width\":0,\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p43796\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p43786\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p43787\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p43788\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAA==\"},\"shape\":[1],\"dtype\":\"int32\",\"order\":\"little\"}],[\"Sector\",{\"type\":\"ndarray\",\"array\":[\"AGRICULTURE\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"Comment\",{\"type\":\"ndarray\",\"array\":[\"<button type=\\\"button\\\" class=\\\"btn btn-secondary btn-sm\\\" data-bs-content=\\\"Food shortages are near, this industry should perform well (if they can get fertiliser).. I will update this as/when I see new opportunites forming. \\\"data-bs-toggle=\\\"popover\\\" data-bs-trigger=\\\"focus\\\" style=\\\"--bs-btn-font-size: .85rem\\\">Details</button>\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"Proportion\",{\"type\":\"ndarray\",\"array\":[20.0],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"angle\",{\"type\":\"ndarray\",\"array\":[1.2566370614359172],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"cumsum_start\",{\"type\":\"ndarray\",\"array\":[0.0],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"cumsum_end\",{\"type\":\"ndarray\",\"array\":[1.2566370614359172],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"percentage_number\",{\"type\":\"ndarray\",\"array\":[20.0],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"percentage_hover\",{\"type\":\"ndarray\",\"array\":[\"20.0\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"percentage_label\",{\"type\":\"ndarray\",\"array\":[\"20%\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"label_x_pos\",{\"type\":\"ndarray\",\"array\":[0.5015905365124674],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"label_y_pos\",{\"type\":\"ndarray\",\"array\":[0.3644268564213334],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p43797\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p43798\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43792\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.7},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.7}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43793\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"hover_glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43794\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43795\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p43816\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p43806\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p43807\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p43808\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AQAAAA==\"},\"shape\":[1],\"dtype\":\"int32\",\"order\":\"little\"}],[\"Sector\",{\"type\":\"ndarray\",\"array\":[\"CHEAP TECH\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"Comment\",{\"type\":\"ndarray\",\"array\":[\"<button type=\\\"button\\\" class=\\\"btn btn-secondary btn-sm\\\" data-bs-content=\\\"Great Tech stocks that have lost 80-90% of their value.. For cheap tech, understand I am referring to tech stocks which have lost a huge amount of value but which still have strong fundamentals. Don't just buy crap! Put in the research!. \\\"data-bs-toggle=\\\"popover\\\" data-bs-trigger=\\\"focus\\\" style=\\\"--bs-btn-font-size: .85rem\\\">Details</button>\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"Proportion\",{\"type\":\"ndarray\",\"array\":[20.0],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"angle\",{\"type\":\"ndarray\",\"array\":[1.2566370614359172],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"cumsum_start\",{\"type\":\"ndarray\",\"array\":[1.2566370614359172],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"cumsum_end\",{\"type\":\"ndarray\",\"array\":[2.5132741228718345],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"percentage_number\",{\"type\":\"ndarray\",\"array\":[20.0],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"percentage_hover\",{\"type\":\"ndarray\",\"array\":[\"20.0\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"percentage_label\",{\"type\":\"ndarray\",\"array\":[\"20%\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"label_x_pos\",{\"type\":\"ndarray\",\"array\":[-0.19159053651246738],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"label_y_pos\",{\"type\":\"ndarray\",\"array\":[0.5896550401029953],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p43817\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p43818\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43812\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#ff7f0e\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.7},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.7}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43813\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#ff7f0e\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"hover_glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43814\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#ff7f0e\"}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43815\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#ff7f0e\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p43836\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p43826\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p43827\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p43828\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AgAAAA==\"},\"shape\":[1],\"dtype\":\"int32\",\"order\":\"little\"}],[\"Sector\",{\"type\":\"ndarray\",\"array\":[\"ENERGY\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"Comment\",{\"type\":\"ndarray\",\"array\":[\"<button type=\\\"button\\\" class=\\\"btn btn-secondary btn-sm\\\" data-bs-content=\\\"(Coal, Oil, Gas, Petroleum & Uranium). The coal sector has one of the lowest PE ratio's right now! (meaning very cheap value stocks).. This allocation suggestion has continued to be extremely accurate throughout 2021-2022.. \\\"data-bs-toggle=\\\"popover\\\" data-bs-trigger=\\\"focus\\\" style=\\\"--bs-btn-font-size: .85rem\\\">Details</button>\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"Proportion\",{\"type\":\"ndarray\",\"array\":[30.0],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"angle\",{\"type\":\"ndarray\",\"array\":[1.8849555921538759],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"cumsum_start\",{\"type\":\"ndarray\",\"array\":[2.5132741228718345],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"cumsum_end\",{\"type\":\"ndarray\",\"array\":[4.39822971502571],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"percentage_number\",{\"type\":\"ndarray\",\"array\":[30.0],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"percentage_hover\",{\"type\":\"ndarray\",\"array\":[\"30.0\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"percentage_label\",{\"type\":\"ndarray\",\"array\":[\"30%\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"label_x_pos\",{\"type\":\"ndarray\",\"array\":[-0.5896550401029953],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"label_y_pos\",{\"type\":\"ndarray\",\"array\":[-0.19159053651246732],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p43837\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p43838\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43832\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#2ca02c\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.7},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.7}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43833\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#2ca02c\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"hover_glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43834\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#2ca02c\"}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43835\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#2ca02c\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p43856\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p43846\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p43847\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p43848\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AwAAAA==\"},\"shape\":[1],\"dtype\":\"int32\",\"order\":\"little\"}],[\"Sector\",{\"type\":\"ndarray\",\"array\":[\"MINING\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"Comment\",{\"type\":\"ndarray\",\"array\":[\"<button type=\\\"button\\\" class=\\\"btn btn-secondary btn-sm\\\" data-bs-content=\\\"(PM) Precious Metals, (EV) Electric Vehicle, Gold Royalties/Streamers.  --------->. But be careful of a rising $USD! This restricts Emerging Markets!.. Unfortunately, mining has suffered due to a rising USD$ & weakening Emerging Markets. \\\"data-bs-toggle=\\\"popover\\\" data-bs-trigger=\\\"focus\\\" style=\\\"--bs-btn-font-size: .85rem\\\">Details</button>\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"Proportion\",{\"type\":\"ndarray\",\"array\":[30.0],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"angle\",{\"type\":\"ndarray\",\"array\":[1.8849555921538759],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"cumsum_start\",{\"type\":\"ndarray\",\"array\":[4.39822971502571],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"cumsum_end\",{\"type\":\"ndarray\",\"array\":[6.283185307179586],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"percentage_number\",{\"type\":\"ndarray\",\"array\":[30.0],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"percentage_hover\",{\"type\":\"ndarray\",\"array\":[\"30.0\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"percentage_label\",{\"type\":\"ndarray\",\"array\":[\"30%\"],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"label_x_pos\",{\"type\":\"ndarray\",\"array\":[0.36442685642133327],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}],[\"label_y_pos\",{\"type\":\"ndarray\",\"array\":[-0.5015905365124675],\"shape\":[1],\"dtype\":\"object\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p43857\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p43858\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43852\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#d62728\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.7},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.7}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43853\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#d62728\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"hover_glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43854\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#d62728\"}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"AnnularWedge\",\"id\":\"p43855\",\"attributes\":{\"x\":{\"type\":\"value\",\"value\":0},\"y\":{\"type\":\"value\",\"value\":0},\"inner_radius\":{\"type\":\"value\",\"value\":0.4},\"outer_radius\":{\"type\":\"value\",\"value\":0.8},\"start_angle\":{\"type\":\"field\",\"field\":\"cumsum_start\"},\"end_angle\":{\"type\":\"field\",\"field\":\"cumsum_end\"},\"line_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":3},\"fill_color\":{\"type\":\"value\",\"value\":\"#d62728\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p43745\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p43771\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p43772\"},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p43773\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p43774\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"bottom_units\":\"canvas\",\"top_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p43775\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p43776\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p43777\"},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p43803\",\"attributes\":{\"renderers\":[{\"id\":\"p43796\"}],\"tooltips\":\"\\n                <div>\\n                    <p style=\\\"margin:0;font-weight:bold;color:grey;\\\">@Sector</p>\\n                    <p style=\\\"padding:0;margin:0;font-weight:bold;\\\">$@Proportion{0,0.00} (@percentage_hover%)</p>\\n                </div>\\n                <style>\\n                    .bk-tooltip {\\n                        background-color: red!important;\\n                    }\\n                </style>\\n            \"}},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p43823\",\"attributes\":{\"renderers\":[{\"id\":\"p43816\"}],\"tooltips\":\"\\n                <div>\\n                    <p style=\\\"margin:0;font-weight:bold;color:grey;\\\">@Sector</p>\\n                    <p style=\\\"padding:0;margin:0;font-weight:bold;\\\">$@Proportion{0,0.00} (@percentage_hover%)</p>\\n                </div>\\n                <style>\\n                    .bk-tooltip {\\n                        background-color: red!important;\\n                    }\\n                </style>\\n            \"}},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p43843\",\"attributes\":{\"renderers\":[{\"id\":\"p43836\"}],\"tooltips\":\"\\n                <div>\\n                    <p style=\\\"margin:0;font-weight:bold;color:grey;\\\">@Sector</p>\\n                    <p style=\\\"padding:0;margin:0;font-weight:bold;\\\">$@Proportion{0,0.00} (@percentage_hover%)</p>\\n                </div>\\n                <style>\\n                    .bk-tooltip {\\n                        background-color: red!important;\\n                    }\\n                </style>\\n            \"}},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p43863\",\"attributes\":{\"renderers\":[{\"id\":\"p43856\"}],\"tooltips\":\"\\n                <div>\\n                    <p style=\\\"margin:0;font-weight:bold;color:grey;\\\">@Sector</p>\\n                    <p style=\\\"padding:0;margin:0;font-weight:bold;\\\">$@Proportion{0,0.00} (@percentage_hover%)</p>\\n                </div>\\n                <style>\\n                    .bk-tooltip {\\n                        background-color: red!important;\\n                    }\\n                </style>\\n            \"}}],\"active_drag\":null}},\"toolbar_location\":null,\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p43764\",\"attributes\":{\"visible\":false,\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p43765\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p43766\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p43767\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p43757\",\"attributes\":{\"visible\":false,\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p43758\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p43759\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p43760\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p43763\",\"attributes\":{\"axis\":{\"id\":\"p43757\"},\"grid_line_color\":null}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p43770\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p43764\"},\"grid_line_color\":null}},{\"type\":\"object\",\"name\":\"LabelSet\",\"id\":\"p43799\",\"attributes\":{\"level\":\"glyph\",\"source\":{\"id\":\"p43786\"},\"x\":{\"type\":\"field\",\"field\":\"label_x_pos\"},\"y\":{\"type\":\"field\",\"field\":\"label_y_pos\"},\"text\":{\"type\":\"field\",\"field\":\"percentage_label\"},\"text_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"text_font_size\":{\"type\":\"value\",\"value\":\"12pt\"},\"text_font_style\":{\"type\":\"value\",\"value\":\"bold\"},\"text_align\":{\"type\":\"value\",\"value\":\"center\"}}},{\"type\":\"object\",\"name\":\"LabelSet\",\"id\":\"p43819\",\"attributes\":{\"level\":\"glyph\",\"source\":{\"id\":\"p43806\"},\"x\":{\"type\":\"field\",\"field\":\"label_x_pos\"},\"y\":{\"type\":\"field\",\"field\":\"label_y_pos\"},\"text\":{\"type\":\"field\",\"field\":\"percentage_label\"},\"text_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"text_font_size\":{\"type\":\"value\",\"value\":\"12pt\"},\"text_font_style\":{\"type\":\"value\",\"value\":\"bold\"},\"text_align\":{\"type\":\"value\",\"value\":\"center\"}}},{\"type\":\"object\",\"name\":\"LabelSet\",\"id\":\"p43839\",\"attributes\":{\"level\":\"glyph\",\"source\":{\"id\":\"p43826\"},\"x\":{\"type\":\"field\",\"field\":\"label_x_pos\"},\"y\":{\"type\":\"field\",\"field\":\"label_y_pos\"},\"text\":{\"type\":\"field\",\"field\":\"percentage_label\"},\"text_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"text_font_size\":{\"type\":\"value\",\"value\":\"12pt\"},\"text_font_style\":{\"type\":\"value\",\"value\":\"bold\"},\"text_align\":{\"type\":\"value\",\"value\":\"center\"}}},{\"type\":\"object\",\"name\":\"LabelSet\",\"id\":\"p43859\",\"attributes\":{\"level\":\"glyph\",\"source\":{\"id\":\"p43846\"},\"x\":{\"type\":\"field\",\"field\":\"label_x_pos\"},\"y\":{\"type\":\"field\",\"field\":\"label_y_pos\"},\"text\":{\"type\":\"field\",\"field\":\"percentage_label\"},\"text_color\":{\"type\":\"value\",\"value\":\"#2C2B2B\"},\"text_font_size\":{\"type\":\"value\",\"value\":\"12pt\"},\"text_font_style\":{\"type\":\"value\",\"value\":\"bold\"},\"text_align\":{\"type\":\"value\",\"value\":\"center\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p43866\",\"attributes\":{\"location\":\"center\",\"border_line_width\":0,\"background_fill_alpha\":0,\"inactive_fill_color\":\"#9fcf2e\",\"inactive_fill_alpha\":0.15,\"click_policy\":\"hide\",\"label_text_color\":\"white\",\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p43805\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"AGRICULTURE\"},\"renderers\":[{\"id\":\"p43796\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p43825\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"CHEAP TECH\"},\"renderers\":[{\"id\":\"p43816\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p43845\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"ENERGY\"},\"renderers\":[{\"id\":\"p43836\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p43865\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"MINING\"},\"renderers\":[{\"id\":\"p43856\"}]}}]}}],\"background_fill_color\":\"#2C2B2B\",\"border_fill_color\":\"#2C2B2B\",\"min_border\":0}}]}};\n  const render_items = [{\"docid\":\"8cd6973e-7b00-476d-a99c-04227123fb13\",\"roots\":{\"p43740\":\"66a189bc-2864-424e-ba86-d3f23408f3f4\"},\"root_ids\":[\"p43740\"]}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p43740"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dashboard.logic.plots import components\n",
    "\n",
    "def donut_chart(\n",
    "    df: pd.DataFrame, \n",
    "    x: str, \n",
    "    y: str,\n",
    "    x_hover: str=None,\n",
    "    y_hover: str=None, \n",
    "    inner_radius: float=0.4,\n",
    "    outer_radius: float=0.8,\n",
    "    label_distance: float=3,\n",
    "    x_range: tuple[float, float]=(-1, 1.0),\n",
    "    percentage_decimal: int=1,\n",
    "    fig_height: int=350,\n",
    "    background_color: str='#212529',\n",
    "    pallette: dict=Category10,\n",
    "    sizing_mode='scale_width',\n",
    "    hover_tooltip: str='default',\n",
    "    legend_place: str='center',\n",
    "    fig_kwargs: dict={},\n",
    "    wedge_kwargs: dict=dict(line_width=3, alpha=0.7),\n",
    "    legend_kwargs: dict=dict(location='center', click_policy=\"hide\",\n",
    "                             label_text_color='white', border_line_width=0,\n",
    "                             inactive_fill_color='#9fcf2e', inactive_fill_alpha=0.15,\n",
    "                             background_fill_alpha=0),\n",
    "    label_kwargs: dict=dict(text_font_size='10pt', text_align='center')\n",
    "    ):\n",
    "    \n",
    "    \n",
    "    # sort df by \"y\"\n",
    "    df = df.sort_values(by=y, ignore_index=True)\n",
    "    \n",
    "    # calculate sector start and end angles\n",
    "    df['angle'] = df[y] / df[y].sum() * 2 * np.pi\n",
    "    df['cumsum_start'] = df['angle'].cumsum(axis='rows').shift(1).fillna(0)\n",
    "    df['cumsum_end'] = df['angle'].cumsum(axis='rows')\n",
    "    \n",
    "    # calculate y percentages for hover & labels\n",
    "    df['percentage_number'] = (df[y] / df[y].sum() * 100).round(percentage_decimal)\n",
    "    df['percentage_hover'] = df['percentage_number'].astype(str)\n",
    "    df['percentage_label'] = df['percentage_number'].apply(lambda x: \"\" if x < 5 else f\"{x:.{percentage_decimal}f}%\")\n",
    "    \n",
    "    # project label text coordinates to polar coordinates\n",
    "    df['label_x_pos'] = np.cos(df['angle'].cumsum() - df['angle'].div(2)) * label_distance * outer_radius/4\n",
    "    df['label_y_pos'] = np.sin(df['angle'].cumsum() - df['angle'].div(2)) * label_distance * outer_radius/4\n",
    "    \n",
    "    # remove assets that are 0\n",
    "    df = df[df[y] > 0]\n",
    "    \n",
    "    # reset dataframe index to start with 0\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # init the figure/canvas for the plot\n",
    "    p = figure(height=fig_height, \n",
    "               toolbar_location=None, \n",
    "               x_range=x_range,\n",
    "               y_range=(-1.0, 1.0),\n",
    "               sizing_mode=sizing_mode,\n",
    "               **fig_kwargs)\n",
    "    \n",
    "    legend_items = []\n",
    "    for idx, color in enumerate(pallette[df.shape[0]]):\n",
    "        \n",
    "        source = ColumnDataSource(df.iloc[idx,:].to_frame().T)\n",
    "        \n",
    "        # create the glyphs renderers\n",
    "        wedge = p.annular_wedge(x=0, y=0, inner_radius=inner_radius, outer_radius=outer_radius, start_angle=\"cumsum_start\", \n",
    "                        end_angle=\"cumsum_end\", source=source, **wedge_kwargs,\n",
    "                        fill_color=color, hover_fill_color=color,\n",
    "                        line_color=background_color, hover_line_color=background_color,\n",
    "                        line_alpha=1, hover_alpha=1, hover_line_alpha=1)\n",
    "        \n",
    "        \n",
    "        label = LabelSet(x='label_x_pos', y='label_y_pos', text='percentage_label',\n",
    "                         source=source, level='glyph', text_color=background_color, **label_kwargs)\n",
    "        \n",
    "        x_hover = x if x_hover is None else x_hover\n",
    "        y_hover = y if y_hover is None else y_hover\n",
    "        \n",
    "        hover_tooltip = hover_tooltip if hover_tooltip != 'default' else \\\n",
    "            f\"\"\"\n",
    "                <div>\n",
    "                    <p style=\"margin:0;font-weight:bold;color:grey;\">@{x_hover}</p>\n",
    "                    <p style=\"padding:0;margin:0;font-weight:bold;\">$@{y_hover}{{0,0.00}} (@percentage_hover%)</p>\n",
    "                </div>\n",
    "                <style>\n",
    "                    .bk-tooltip {{\n",
    "                        background-color: red!important;\n",
    "                    }}\n",
    "                </style>\n",
    "            \"\"\"\n",
    "        \n",
    "        p.add_layout(label)\n",
    "        p.add_tools(HoverTool(renderers=[wedge],\n",
    "                              tooltips=hover_tooltip))\n",
    "\n",
    "        legend_items.append(LegendItem(label=df[x][idx], renderers=[wedge]))\n",
    "\n",
    "    # legend\n",
    "    legend = Legend(items=legend_items,  **legend_kwargs)\n",
    "    \n",
    "    p.add_layout(legend, place=legend_place)\n",
    "\n",
    "    \n",
    "    # figure attributes\n",
    "    p.toolbar.active_drag = None\n",
    "    p.axis.axis_label = None\n",
    "    p.axis.visible = False\n",
    "    p.grid.grid_line_color = None\n",
    "    \n",
    "    \n",
    "    p.min_border=0\n",
    "    p.outline_line_alpha=0\n",
    "    p.outline_line_width=0\n",
    "    p.outline_line_color = p.background_fill_color = p.border_fill_color = background_color\n",
    "\n",
    "    return show(p)\n",
    "\n",
    "h_tooltip = f\"\"\"\n",
    "                <div>\n",
    "                    <p style=\"margin:0;font-weight:bold;color:grey;\">@Sector</p>\n",
    "                    <p style=\"padding:0;margin:0;font-weight:bold;text-align:center;\">@percentage_hover{{0}}%</p>\n",
    "                </div>\n",
    "                <style>\n",
    "                    .bk-root .bk-tooltip {{\n",
    "                        background-color: red;\n",
    "                    }}\n",
    "                </style>\n",
    "            \"\"\"\n",
    "\n",
    "donut_chart(\n",
    "        df=df_sectors_plot.iloc[1:,],\n",
    "        x='Sector',\n",
    "        y='Proportion',\n",
    "        sizing_mode='fixed',\n",
    "        background_color='#2C2B2B',\n",
    "        percentage_decimal=0,\n",
    "        fig_height=500,\n",
    "        label_distance=3.1,\n",
    "        label_kwargs=dict(text_font_size='12pt', text_align='center', text_font_style='bold'),\n",
    "        legend_place='center',\n",
    "        fig_kwargs={'width':500}\n",
    "    )\n",
    "#obj_js, obj_div = components(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['a'] + ['b']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Announcements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feb 2023</td>\n",
       "      <td>Rather than save all your CASH in the bank (u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan 2023</td>\n",
       "      <td>Property (Castle) Purchase 23rd Jan 2023. Cash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan 2023</td>\n",
       "      <td>As central banks tighten (QT + Interest rate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan 2023</td>\n",
       "      <td>I wouldn't be surprised if we see a small ral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dec 2022</td>\n",
       "      <td>No change to last month. 2022 financial forec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nov 2022</td>\n",
       "      <td>Asset prices are now beginning to fall in cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Oct 2022</td>\n",
       "      <td>Cash is king right now. Assets are finally st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sep 2022</td>\n",
       "      <td>Cash currently held between multiple bank acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aug 2022</td>\n",
       "      <td>As per last month, I am still accumulating ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jul 2022</td>\n",
       "      <td>I'm following my February plan of going to CA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date                                               text\n",
       "0  Feb 2023   Rather than save all your CASH in the bank (u...\n",
       "1  Jan 2023  Property (Castle) Purchase 23rd Jan 2023. Cash...\n",
       "2  Jan 2023   As central banks tighten (QT + Interest rate ...\n",
       "3  Jan 2023   I wouldn't be surprised if we see a small ral...\n",
       "4  Dec 2022   No change to last month. 2022 financial forec...\n",
       "5  Nov 2022   Asset prices are now beginning to fall in cor...\n",
       "6  Oct 2022   Cash is king right now. Assets are finally st...\n",
       "7  Sep 2022   Cash currently held between multiple bank acc...\n",
       "8  Aug 2022   As per last month, I am still accumulating ca...\n",
       "9  Jul 2022   I'm following my February plan of going to CA..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dashboard.route.investments import df_dict, df_hist\n",
    "import re\n",
    "\n",
    "df_a = df_dict['announce'].copy()\n",
    "df_a = df_a.reset_index(drop=True)\n",
    "df_a = df_a[0].str.split(pat=':', n=1, expand=True)\n",
    "df_a.columns = ['date', 'text']\n",
    "no_date_idx = df_a['date'].str.contains(r\"property for £980k\", case=False).argmax()\n",
    "df_a.loc[no_date_idx, 'text'] = df_a.loc[no_date_idx, 'date']\n",
    "df_a.loc[no_date_idx, 'date'] = re.search(r\"[A-Z]{1}[a-z]{2}\\s202\\d{1}\", df_a.loc[no_date_idx, 'text'])[0]\n",
    "\n",
    "df_a\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stocks Watchlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOCKS_WATCH_URL = \"https://docs.google.com/spreadsheets/d/12-GISr1efphjtpuJLCfQzI2akNXxaJ1iabsG24ib71c/edit#gid=845083323\"\n",
    "\n",
    "# Read in summary DF and drop empty rows\n",
    "df = read_gsheet(\n",
    "    STOCKS_WATCH_URL, \n",
    "    header=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find df header row index using regex pattern\n",
    "header_idx = df.apply(lambda x: x.str.contains(\"Neil's Value\", case=False)).any(axis='columns').argmax()\n",
    "\n",
    "# separate disclaimer and df\n",
    "df_disclaimer = df.iloc[:header_idx-1, 0]\n",
    "df_watch = df.iloc[header_idx:,]\n",
    "\n",
    "# set first row as header & reset row idxs\n",
    "df_watch.columns = df_watch.iloc[0].values\n",
    "df_watch = df_watch.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "# Generate buttons for 'Notes' column\n",
    "df_watch.Notes[df_watch.Notes.notna()] = df_watch.Notes[df_watch.Notes.notna()].apply(comment_button)\n",
    "df_watch = df_watch.fillna(\"\")\n",
    "\n",
    "# Color Ratings based on category\n",
    "rating_colormap = {'Sig Undervalued':'green', 'Mod Undervalued':'blue', 'Fair Value':'grey', 'Value Trap?':'red'}\n",
    "#df_watch[\"rating_color\"] = df_watch.Rating.map(rating_colormap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>color</th>\n",
       "      <th>icon_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please make your own copy of the stocks sectio...</td>\n",
       "      <td>success</td>\n",
       "      <td>check-lg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These stocks were found using the techniques t...</td>\n",
       "      <td>success</td>\n",
       "      <td>check-lg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neil's Stocks Strategy: 80% into Index funds, ...</td>\n",
       "      <td>success</td>\n",
       "      <td>check-lg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>These Valuations are for the purpose of Long T...</td>\n",
       "      <td>warning</td>\n",
       "      <td>exclamation-triangle-fill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOTE! Many of the metrics below have to be man...</td>\n",
       "      <td>warning</td>\n",
       "      <td>exclamation-triangle-fill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AT THIS TIME, I AM OUT OF ALL STOCKS. PLEASE D...</td>\n",
       "      <td>danger</td>\n",
       "      <td>exclamation-octagon-fill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                info    color  \\\n",
       "1  Please make your own copy of the stocks sectio...  success   \n",
       "3  These stocks were found using the techniques t...  success   \n",
       "4  Neil's Stocks Strategy: 80% into Index funds, ...  success   \n",
       "0  These Valuations are for the purpose of Long T...  warning   \n",
       "2  NOTE! Many of the metrics below have to be man...  warning   \n",
       "5  AT THIS TIME, I AM OUT OF ALL STOCKS. PLEASE D...   danger   \n",
       "\n",
       "                     icon_id  \n",
       "1                   check-lg  \n",
       "3                   check-lg  \n",
       "4                   check-lg  \n",
       "0  exclamation-triangle-fill  \n",
       "2  exclamation-triangle-fill  \n",
       "5   exclamation-octagon-fill  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_disclaimer.copy()\n",
    "\n",
    "# add period end of the sentence if not so\n",
    "df1 = df1.to_frame().rename(columns={0: 'info'})\n",
    "df1.loc[:,'info'] = [x + '.' if x[-1] != '.' else x for x in df1['info']]\n",
    "\n",
    "df_disc = df1.copy()\n",
    "\n",
    "df_disc['color'] = ['warning', 'success', 'warning', 'success', 'success', 'danger']\n",
    "df_disc['color'] = pd.Categorical(df_disc['color'],\n",
    "                                  categories=['success', 'warning', 'danger'],\n",
    "                                  ordered=True)\n",
    "icon_dict = {'warning': 'exclamation-triangle-fill', 'success': 'check-lg', 'danger':'exclamation-octagon-fill'}\n",
    "df_disc['icon_id'] = df_disc['color'].map(icon_dict)\n",
    "df_disc = df_disc.sort_values('color')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dashboard_invest-5AWLHTjn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95bc9e6ef71e31cc08e5be64fcf800fc74ede588d28797baac94c8521371730c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
